{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CELINE documentation","text":"<p>Documentation for the CELINE project</p>"},{"location":"ontologies/","title":"CELINE Ontology","text":"<p>This directory contains the semantic artifacts used in the CELINE project to support:</p> <ul> <li>semantic interoperability across datasets</li> <li>Digital Twins (WP3)</li> <li>Demonstrators, KPIs, and evaluation (WP5)</li> <li>mapping from tabular data to RDF / JSON-LD</li> </ul> <p>The CELINE ontology is not a standalone domain ontology, but a unified ontology profile that aligns and connects established standards (SAREF, SOSA, BIGG, SEAS, EM-KPI) into a coherent semantic target for the CELINE ecosystem.</p>"},{"location":"ontologies/#contents","title":"Contents","text":""},{"location":"ontologies/#core-ontology-artifacts","title":"Core ontology artifacts","text":"<ul> <li> <p>CELINE ontology documentation   Documentation of the CELINE ontology</p> </li> <li> <p>CELINE ontology (Turtle)   The formal OWL/RDF definition of the CELINE Unified Ontology Profile.   Defines CELINE classes and properties and aligns them with SAREF, SOSA, BIGG, SEAS, and EM-KPI.</p> </li> <li> <p>CELINE SHACL shapes   SHACL shapes defining semantic constraints on the RDF graph after JSON-LD expansion.   Used to validate observations, time series, meters, energy communities, and KPIs.</p> </li> <li> <p>CELINE JSON-LD context   JSON-LD <code>@context</code> defining prefixes, aliases, and mappings used by CELINE APIs and data pipelines.   This is the primary entry point for developers producing JSON-LD payloads.</p> </li> <li> <p>CELINE JSON Schema   JSON Schema used at API boundaries to validate incoming JSON-LD payloads before semantic expansion.</p> </li> </ul>"},{"location":"ontologies/#repository-mapping-configuration","title":"Repository &amp; mapping configuration","text":"<ul> <li> <p>Open repository configuration   YAML configuration listing datasets, governance metadata, and extension points for ontology mapping.</p> </li> <li> <p>Open repository JSON Schema   JSON Schema defining the structure of the dataset catalogue and repository configuration used by CELINE tooling.</p> </li> </ul>"},{"location":"ontologies/#how-these-artifacts-work-together","title":"How these artifacts work together","text":"<p>The CELINE semantic stack follows a layered validation and mapping approach:</p> <ol> <li>Tabular data is exposed via dataset APIs  </li> <li>Mapping definitions bind dataset schemas to ontology classes and properties  </li> <li>JSON-LD is generated using <code>celine.jsonld</code> </li> <li>JSON Schema (<code>celine.schema.json</code>) validates payload structure at the API level  </li> <li>JSON-LD expansion produces RDF  </li> <li>SHACL validation (<code>celine.shacl.ttl</code>) enforces semantic correctness  </li> <li>Validated data is ingested into the CELINE Digital Twin / Knowledge Graph</li> </ol> <p>This separation ensures: - developer-friendly APIs - strict semantic validation - long-term interoperability</p>"},{"location":"ontologies/#design-principles","title":"Design principles","text":"<ul> <li>Standards first: reuse ETSI SAREF, W3C SOSA/SSN, BIGG, SEAS, EM-KPI</li> <li>Thin CELINE layer: only project-specific glue concepts are defined</li> <li>Modular &amp; versionable: artifacts can evolve independently</li> <li>Tool-friendly: compatible with rdflib, JSON-LD, SHACL engines</li> </ul>"},{"location":"ontologies/#intended-audience","title":"Intended audience","text":"<ul> <li>CELINE developers integrating data sources</li> <li>WP3 Digital Twin engineers</li> <li>WP5 demonstrator and KPI designers</li> <li>Data governance and interoperability stakeholders</li> </ul>"},{"location":"ontologies/#versioning-publication","title":"Versioning &amp; publication","text":"<p>These ontology artifacts are published via GitHub Pages to provide stable, resolvable URLs suitable for:</p> <ul> <li>JSON-LD contexts</li> <li>ontology references in catalogues</li> <li>external integrations</li> </ul> <p>Always prefer versioned URLs when referencing ontology artifacts in mappings or production systems.</p>"},{"location":"ontologies/#questions-contributions","title":"Questions &amp; contributions","text":"<p>For questions, discussions, or proposed changes to the CELINE ontology profile, please refer to the main CELINE repository or open an issue in the relevant project repository.</p>"},{"location":"ontologies/celine/","title":"CELINE Ontology","text":"<p>Namespace</p> <p><code>https://celine-eu.github.io/ontologies/celine#</code></p>"},{"location":"ontologies/celine/#classes","title":"Classes","text":"<ul> <li>Asset</li> <li>CO2Factor</li> <li>EnergyCommunity</li> <li>EnergyKPI</li> <li>FlexibilityEvent</li> <li>Forecast</li> <li>Meter</li> <li>Observation</li> <li>Prosumer</li> <li>Tariff</li> <li>TimeSeries</li> </ul>"},{"location":"ontologies/celine/#properties","title":"Properties","text":"<ul> <li>evaluatedBy</li> <li>hasCO2Factor</li> <li>hasFlexibilityEvent</li> <li>hasForecast</li> <li>hasMember</li> <li>hasMeter</li> <li>hasObservation</li> <li>hasTariff</li> <li>hasTimeSeries</li> <li>isLocatedIn</li> <li>measuredConsumption</li> <li>measuredProduction</li> <li>ownsAsset</li> <li>pointTime</li> <li>pointValue</li> <li>timestamp</li> <li>value</li> </ul>"},{"location":"ontologies/celine/#asset","title":"Asset","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#Asset</code></p> <p>Label Asset</p> <p> </p>"},{"location":"ontologies/celine/#co2factor","title":"CO2Factor","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#CO2Factor</code></p> <p>Label CO2 Emission Factor</p> <p> </p>"},{"location":"ontologies/celine/#energycommunity","title":"EnergyCommunity","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#EnergyCommunity</code></p> <p>Label Energy Community</p> <p> </p>"},{"location":"ontologies/celine/#energykpi","title":"EnergyKPI","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#EnergyKPI</code></p> <p>Label Energy KPI</p> <p> </p>"},{"location":"ontologies/celine/#flexibilityevent","title":"FlexibilityEvent","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#FlexibilityEvent</code></p> <p>Label Flexibility Event</p> <p> </p>"},{"location":"ontologies/celine/#forecast","title":"Forecast","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#Forecast</code></p> <p>Label Forecast</p> <p> </p>"},{"location":"ontologies/celine/#meter","title":"Meter","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#Meter</code></p> <p>Label Meter</p> <p> </p>"},{"location":"ontologies/celine/#observation","title":"Observation","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#Observation</code></p> <p>Label Observation</p> <p> </p>"},{"location":"ontologies/celine/#prosumer","title":"Prosumer","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#Prosumer</code></p> <p>Label Prosumer</p> <p> </p>"},{"location":"ontologies/celine/#tariff","title":"Tariff","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#Tariff</code></p> <p>Label Tariff</p> <p> </p>"},{"location":"ontologies/celine/#timeseries","title":"TimeSeries","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#TimeSeries</code></p> <p>Label Time Series</p> <p> </p>"},{"location":"ontologies/celine/#evaluatedby","title":"evaluatedBy","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#evaluatedBy</code></p> <p>Label evaluated by</p> <p> </p>"},{"location":"ontologies/celine/#hasco2factor","title":"hasCO2Factor","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#hasCO2Factor</code></p> <p>Label has CO2 factor</p> <p> </p>"},{"location":"ontologies/celine/#hasflexibilityevent","title":"hasFlexibilityEvent","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#hasFlexibilityEvent</code></p> <p>Label has flexibility event</p> <p> </p>"},{"location":"ontologies/celine/#hasforecast","title":"hasForecast","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#hasForecast</code></p> <p>Label has forecast</p> <p> </p>"},{"location":"ontologies/celine/#hasmember","title":"hasMember","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#hasMember</code></p> <p>Label has member</p> <p> </p>"},{"location":"ontologies/celine/#hasmeter","title":"hasMeter","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#hasMeter</code></p> <p>Label has meter</p> <p> </p>"},{"location":"ontologies/celine/#hasobservation","title":"hasObservation","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#hasObservation</code></p> <p>Label has observation</p> <p> </p>"},{"location":"ontologies/celine/#hastariff","title":"hasTariff","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#hasTariff</code></p> <p>Label has tariff</p> <p> </p>"},{"location":"ontologies/celine/#hastimeseries","title":"hasTimeSeries","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#hasTimeSeries</code></p> <p>Label has time series</p> <p> </p>"},{"location":"ontologies/celine/#islocatedin","title":"isLocatedIn","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#isLocatedIn</code></p> <p>Label is located in</p> <p> </p>"},{"location":"ontologies/celine/#measuredconsumption","title":"measuredConsumption","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#measuredConsumption</code></p> <p>Label measured consumption</p> <p> </p>"},{"location":"ontologies/celine/#measuredproduction","title":"measuredProduction","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#measuredProduction</code></p> <p>Label measured production</p> <p> </p>"},{"location":"ontologies/celine/#ownsasset","title":"ownsAsset","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#ownsAsset</code></p> <p>Label owns asset</p> <p> </p>"},{"location":"ontologies/celine/#pointtime","title":"pointTime","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#pointTime</code></p> <p>Label point time</p> <p> </p>"},{"location":"ontologies/celine/#pointvalue","title":"pointValue","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#pointValue</code></p> <p>Label point value</p> <p> </p>"},{"location":"ontologies/celine/#timestamp","title":"timestamp","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#timestamp</code></p> <p>Label timestamp</p> <p> </p>"},{"location":"ontologies/celine/#value","title":"value","text":"<p>IRI <code>https://celine-eu.github.io/ontologies/celine#value</code></p> <p>Label value</p>"},{"location":"projects/","title":"Tools","text":"<p>CELINE tools and services.</p>"},{"location":"projects/#dashboards","title":"Dashboards","text":"<ul> <li>celine-dashboards</li> </ul>"},{"location":"projects/#digital-twin","title":"Digital Twin","text":"<ul> <li>celine-digital-twin</li> </ul>"},{"location":"projects/#dataset-api","title":"Dataset API","text":"<ul> <li>dataset-api</li> </ul>"},{"location":"projects/#utils","title":"Utils","text":"<ul> <li>celine-utils</li> </ul>"},{"location":"projects/#open-data-pipelines","title":"Open Data Pipelines","text":"<ul> <li>celine-pipelines</li> </ul>"},{"location":"projects/#infrastructure","title":"Infrastructure","text":"<ul> <li>celine-infra</li> </ul>"},{"location":"projects/celine-dashboards/","title":"CELINE Dashboards","text":"<p>This repository provides the CELINE Dashboards stack, a production\u2011ready analytics environment built around Apache Superset and Jupyter, secured through Keycloak and oauth2\u2011proxy, and fronted by Caddy.</p> <p>The project is designed to deliver: - centralized SSO authentication, - consistent authorization across services, - Docker\u2011first local development and deployment, - extensible, auditable security logic aligned with the CELINE platform.</p>"},{"location":"projects/celine-dashboards/#overview","title":"Overview","text":"<p>The stack exposes multiple web services (currently Superset and Jupyter) behind a single authentication boundary. Authentication is fully delegated to Keycloak via oauth2\u2011proxy, while each application consumes identity and authorization data from trusted headers or JWTs.</p> <p>Key goals: - No local passwords in Superset or Jupyter - Automatic user provisioning - Role and group synchronization from Keycloak - Support for browser users and service / CLI tokens</p>"},{"location":"projects/celine-dashboards/#architecture","title":"Architecture","text":"<p>High\u2011level flow:</p> <pre><code>Browser / CLI\n    |\n    v\nCaddy (reverse proxy)\n    |\n    +--&gt; oauth2-proxy ----&gt; Keycloak (OIDC)\n    |\n    +--&gt; Superset\n    |\n    +--&gt; Jupyter\n</code></pre> <p>Authentication and authorization flow:</p> <ol> <li>User accesses a protected service (Superset or Jupyter).</li> <li>Caddy delegates authentication to oauth2\u2011proxy (<code>forward_auth</code>).</li> <li>oauth2\u2011proxy authenticates the user via Keycloak (OIDC).</li> <li>Identity headers and access tokens are forwarded back to Caddy.</li> <li>Requests are proxied to the target service.</li> <li>Each service validates and enforces authorization locally:</li> <li>Superset via a custom <code>SecurityManager</code></li> <li>Jupyter via a JWT\u2011based authorizer</li> </ol>"},{"location":"projects/celine-dashboards/#repository-structure","title":"Repository Structure","text":"<pre><code>.\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 caddy/              # Reverse proxy configuration\n\u2502   \u251c\u2500\u2500 keycloak/           # Realm, clients, groups, and demo users\n\u2502   \u251c\u2500\u2500 oauth2-proxy/       # oauth2-proxy configuration\n\u2502   \u251c\u2500\u2500 superset/           # Superset configuration and env files\n\u2502   \u2514\u2500\u2500 jupyter/            # Jupyter server configuration\n\u2502\n\u251c\u2500\u2500 packages/\n\u2502   \u251c\u2500\u2500 celine-superset/    # Custom Superset authentication extension\n\u2502   \u2514\u2500\u2500 jupyter_jwt_auth/   # JWT-based Jupyter authorizer\n\u2502\n\u251c\u2500\u2500 Dockerfile              # Superset image\n\u251c\u2500\u2500 Dockerfile.jupyter      # Jupyter image\n\u251c\u2500\u2500 docker-compose.yaml     # Full local stack\n\u251c\u2500\u2500 version.txt             # Superset image version\n\u251c\u2500\u2500 version.jupyter.txt     # Jupyter image version\n\u251c\u2500\u2500 taskfile.yaml           # Common developer tasks\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"projects/celine-dashboards/#services","title":"Services","text":""},{"location":"projects/celine-dashboards/#superset","title":"Superset","text":"<ul> <li>Authentication type: <code>AUTH_REMOTE_USER</code></li> <li>Login and logout fully delegated to oauth2\u2011proxy</li> <li>Custom <code>OAuth2ProxySecurityManager</code>:</li> <li>validates JWT signatures via Keycloak JWKS</li> <li>auto\u2011creates users on first login</li> <li>synchronizes roles on each login</li> <li>maps Keycloak groups to Superset roles</li> </ul> <p>Group\u2011to\u2011role mapping is defined in:</p> <pre><code>packages/celine-superset/celine_superset/auth/roles.py\n</code></pre> <p>Example:</p> <pre><code>GROUP_TO_SUPERSET_ROLE = {\n    \"admins\": \"Admin\",\n    \"managers\": \"Alpha\",\n    \"editors\": \"Beta\",\n    \"viewers\": \"Gamma\",\n}\n</code></pre>"},{"location":"projects/celine-dashboards/#jupyter","title":"Jupyter","text":"<ul> <li>No local token or password authentication</li> <li>Access controlled by a custom JWT authorizer</li> <li>Authorization decisions based on JWT group claims</li> <li>Intended for notebook execution under the same SSO boundary</li> </ul> <p>Only users in the <code>/admins</code> group currently receive full access by default.</p>"},{"location":"projects/celine-dashboards/#authentication-identity","title":"Authentication &amp; Identity","text":""},{"location":"projects/celine-dashboards/#keycloak","title":"Keycloak","text":"<p>The repository ships with a ready\u2011to\u2011import Keycloak realm definition:</p> <ul> <li>Realm: <code>celine</code></li> <li>Clients:</li> <li><code>oauth2_proxy</code> (browser SSO)</li> <li><code>celine-cli</code> (service and CLI tokens)</li> <li>Groups:</li> <li><code>/admins</code></li> <li><code>/managers</code></li> <li><code>/editors</code></li> <li><code>/viewers</code></li> </ul> <p>Demo users are included for local development.</p>"},{"location":"projects/celine-dashboards/#oauth2proxy","title":"oauth2\u2011proxy","text":"<p>oauth2\u2011proxy acts as the single authentication gateway:</p> <ul> <li>Handles browser login flows</li> <li>Injects identity headers and access tokens</li> <li>Supports service tokens via <code>skip_jwt_bearer_tokens</code></li> <li>Shares cookies across <code>*.celine.localhost</code></li> </ul> <p>It is exposed through a dedicated SSO endpoint:</p> <pre><code>http://sso.celine.localhost\n</code></pre>"},{"location":"projects/celine-dashboards/#local-development","title":"Local Development","text":""},{"location":"projects/celine-dashboards/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker</li> <li>Docker Compose</li> <li>Task (https://taskfile.dev)</li> </ul>"},{"location":"projects/celine-dashboards/#setup","title":"Setup","text":"<ol> <li>Clone the repository</li> </ol> <pre><code>git clone https://github.com/celine-eu/celine-dashboards.git\ncd celine-dashboards\n</code></pre> <ol> <li>Initialize environment files</li> </ol> <pre><code>task ensure-env\n</code></pre> <ol> <li>Start the full stack</li> </ol> <pre><code>docker compose up -d\n</code></pre> <ol> <li> <p>Access services</p> </li> <li> <p>Superset: http://superset.celine.localhost</p> </li> <li>Jupyter: http://jupyter.celine.localhost</li> <li>SSO / oauth2\u2011proxy: http://sso.celine.localhost</li> <li>Keycloak: http://keycloak.celine.localhost</li> </ol>"},{"location":"projects/celine-dashboards/#docker-images-ci","title":"Docker Images &amp; CI","text":"<p>Docker images are built and published automatically via GitHub Actions.</p>"},{"location":"projects/celine-dashboards/#superset_1","title":"Superset","text":"<pre><code>ghcr.io/celine-eu/superset:&lt;version&gt;\nghcr.io/celine-eu/superset:latest\n</code></pre> <p>The version is defined in <code>version.txt</code>.</p>"},{"location":"projects/celine-dashboards/#jupyter_1","title":"Jupyter","text":"<pre><code>ghcr.io/celine-eu/jupyter:&lt;version&gt;\nghcr.io/celine-eu/jupyter:latest\n</code></pre> <p>The version is defined in <code>version.jupyter.txt</code>.</p> <p>Images are rebuilt automatically when relevant source or configuration files change.</p>"},{"location":"projects/celine-dashboards/#extensibility","title":"Extensibility","text":"<p>This repository is intentionally structured to allow:</p> <ul> <li>swapping or extending identity providers,</li> <li>customizing JWT claim formats,</li> <li>adding new services behind the same SSO boundary,</li> <li>refining role\u2011based access control logic.</li> </ul> <p>Authentication logic is isolated in reusable Python packages and kept stateless.</p>"},{"location":"projects/celine-dashboards/#contributing","title":"Contributing","text":"<p>Contributions are welcome.</p> <p>Guidelines: - Keep authentication logic stateless and defensive - Do not introduce local login mechanisms - Ensure JWT validation remains explicit and verifiable - Add tests for any auth\u2011related changes</p>"},{"location":"projects/celine-dashboards/#license","title":"License","text":"<p>Copyright \u00a9 2025 Spindox Labs</p> <p>Licensed under the Apache License, Version 2.0. You may not use this file except in compliance with the License.</p> <p>See http://www.apache.org/licenses/LICENSE-2.0 for details.</p>"},{"location":"projects/celine-digital-twin/","title":"CELINE Digital Twin (DT)","text":"<p>The CELINE Digital Twin is a modular, production\u2011ready runtime for building, executing, and exposing Digital Twin applications for energy systems such as Renewable Energy Communities (RECs), microgrids, and scenario\u2011based simulations.</p> <p>This repository provides a stable Digital Twin core and a module\u2011driven extension model that allows teams to develop, deploy, and evolve multiple DT applications independently while sharing a common runtime.</p>"},{"location":"projects/celine-digital-twin/#documentation","title":"Documentation","text":"<ul> <li>Concepts</li> <li>Create a new module</li> </ul>"},{"location":"projects/celine-digital-twin/#what-this-repository-provides","title":"What this repository provides","text":"<ul> <li>A FastAPI\u2011based DT runtime</li> <li>A module system for loading DT capabilities at startup</li> <li>An app\u2011oriented execution model</li> <li>Strong typing and schema introspection</li> <li>A clean separation between:</li> <li>runtime orchestration</li> <li>domain logic</li> <li>data access</li> <li>A reference battery sizing simulation</li> </ul> <p>This project is a foundation, not a turnkey product. It is designed to scale in complexity without accumulating architectural debt.</p>"},{"location":"projects/celine-digital-twin/#core-capabilities","title":"Core capabilities","text":""},{"location":"projects/celine-digital-twin/#modular-dt-runtime","title":"Modular DT runtime","text":"<ul> <li>DT functionality is delivered through modules</li> <li>Modules are configured via YAML and loaded dynamically</li> <li>Each module may register one or more DT apps</li> </ul>"},{"location":"projects/celine-digital-twin/#apporiented-execution","title":"App\u2011oriented execution","text":"<ul> <li>Each DT app is a self\u2011contained capability</li> <li>Apps can be:</li> <li>simulations</li> <li>analyses</li> <li>adapters to external datasets</li> <li>Apps are independently executable and discoverable</li> </ul>"},{"location":"projects/celine-digital-twin/#strong-contracts-schemas","title":"Strong contracts &amp; schemas","text":"<ul> <li>Inputs and outputs are defined using Pydantic models</li> <li>Schemas are exposed dynamically via API</li> <li>Clients can discover contracts at runtime</li> </ul>"},{"location":"projects/celine-digital-twin/#transportagnostic-execution","title":"Transport\u2011agnostic execution","text":"<ul> <li>Apps do not depend on FastAPI or HTTP</li> <li>The same execution path is used for:</li> <li>REST API</li> <li>unit tests</li> <li>batch jobs</li> <li>future workers</li> </ul>"},{"location":"projects/celine-digital-twin/#ontologyaware-storagepragmatic","title":"Ontology\u2011aware, storage\u2011pragmatic","text":"<ul> <li>Ontologies define semantic intent</li> <li>Relational storage is used internally where needed</li> <li>Ontology loading is centralized and configurable</li> </ul>"},{"location":"projects/celine-digital-twin/#running-the-dt-runtime","title":"Running the DT runtime","text":"<p>Start the runtime in development mode:</p> <pre><code>uv run uvicorn celine.dt.main:create_app --reload\n</code></pre> <p>Health check:</p> <pre><code>curl http://localhost:8000/health\n</code></pre>"},{"location":"projects/celine-digital-twin/#discover-available-apps","title":"Discover available apps","text":"<pre><code>curl http://localhost:8000/apps\n</code></pre> <p>Example response:</p> <pre><code>[\n  { \"key\": \"battery-sizing\", \"version\": \"2.0.0\" }\n]\n</code></pre>"},{"location":"projects/celine-digital-twin/#inspect-app-contracts","title":"Inspect app contracts","text":"<pre><code>curl http://localhost:8000/apps/battery-sizing/describe\n</code></pre> <p>This endpoint returns the input and output JSON Schemas derived from the app mappers and models.</p>"},{"location":"projects/celine-digital-twin/#run-the-battery-sizing-simulation","title":"Run the battery sizing simulation","text":"<pre><code>curl -X POST http://localhost:8000/apps/battery-sizing/run   -H \"Content-Type: application/json\"   -d '{\n    \"demand\": { \"values\": [5, 5, 5, 5], \"timestep_hours\": 1 },\n    \"pv\": { \"values\": [0, 10, 10, 0], \"timestep_hours\": 1 },\n    \"roundtrip_efficiency\": 0.9,\n    \"max_capacity_kwh\": 20\n  }'\n</code></pre> <p>Example response:</p> <pre><code>{\n  \"@type\": \"BatterySizingResult\",\n  \"capacityKWh\": 20.0,\n  \"gridImportKWh\": 0.0,\n  \"selfConsumptionRatio\": 1.0\n}\n</code></pre>"},{"location":"projects/celine-digital-twin/#license","title":"License","text":"<p>Copyright &gt;=2025 Spindox Labs</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0</p> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/","title":"Concepts","text":"<p>This document explains the core architectural concepts of the CELINE Digital Twin runtime and how they interact.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#digital-twin-core","title":"Digital Twin Core","text":"<p>The DT core is responsible for: - application lifecycle - module loading - execution orchestration - API exposure - shared infrastructure concerns</p> <p>It deliberately avoids domain\u2011specific logic.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#modules","title":"Modules","text":"<p>A DT module is a deployable unit of functionality.</p> <p>A module: - has a <code>name</code> and <code>version</code> - is enabled via configuration - registers apps into the registry</p> <p>Contract:</p> <pre><code>class DTModule:\n    name: str\n    version: str\n    def register(self, registry: DTRegistry) -&gt; None\n</code></pre> <p>Modules are loaded at startup and validated against configuration constraints.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#registry","title":"Registry","text":"<p>The DTRegistry is the central in\u2011memory catalog.</p> <p>It tracks: - loaded modules - registered apps - active ontology</p> <p>It also provides introspection for discovery and documentation.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#apps","title":"Apps","text":"<p>A DT app represents a single runnable Digital Twin capability.</p> <pre><code>class DTApp[I, O]:\n    key: str\n    version: str\n    async def run(self, inputs: I, context: RunContext) -&gt; O\n</code></pre> <p>Apps: - contain pure domain logic - are unaware of HTTP, databases, or frameworks - receive all context explicitly</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#mappers","title":"Mappers","text":"<p>Mappers define the public contract of an app.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#inputmappert","title":"InputMapper[T]","text":"<ul> <li>converts raw payload \u2192 typed input model</li> <li>defines how external clients interact with the app</li> </ul>"},{"location":"projects/celine-digital-twin/docs/concepts/#outputmappert","title":"OutputMapper[T]","text":"<ul> <li>converts domain result \u2192 serializable output</li> <li>defines the external representation</li> </ul> <p>Mappers are generic and type\u2011safe.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#timeseries","title":"TimeSeries","text":"<p><code>TimeSeries[T]</code> is a reusable primitive representing ordered values with a fixed timestep.</p> <pre><code>TimeSeries(values=[...], timestep_hours=1.0)\n</code></pre> <p>It is used consistently across simulations and KPIs.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#runcontext","title":"RunContext","text":"<p><code>RunContext</code> carries execution metadata and shared services.</p> <p>Fields include: - request id - timestamp - injected services - optional transport metadata</p> <p>This ensures apps remain testable and transport\u2011agnostic.</p>"},{"location":"projects/celine-digital-twin/docs/concepts/#runner","title":"Runner","text":"<p><code>DTAppRunner</code> is the single execution engine.</p> <p>Execution flow: 1. resolve app from registry 2. apply input mapper 3. execute app logic 4. apply output mapper</p> <p>All execution paths (API, tests, batch) use the same runner.</p>"},{"location":"projects/celine-digital-twin/docs/create-module/","title":"Create a new DT module","text":"<p>This guide explains how to create a new Digital Twin module from a developer perspective.</p>"},{"location":"projects/celine-digital-twin/docs/create-module/#1-create-the-module-structure","title":"1. Create the module structure","text":"<pre><code>celine/dt/modules/my_module/\n\u251c\u2500\u2500 app.py\n\u251c\u2500\u2500 models.py\n\u251c\u2500\u2500 mappers.py\n\u2514\u2500\u2500 module.py\n</code></pre>"},{"location":"projects/celine-digital-twin/docs/create-module/#2-define-input-and-output-models","title":"2. Define input and output models","text":"<p>Use Pydantic models to define the app contract.</p> <pre><code>class MyInputs(BaseModel):\n    ...\n\nclass MyResult(BaseModel):\n    ...\n</code></pre>"},{"location":"projects/celine-digital-twin/docs/create-module/#3-implement-the-app","title":"3. Implement the app","text":"<pre><code>class MyApp:\n    key = \"my-app\"\n    version = \"1.0.0\"\n\n    async def run(self, inputs: MyInputs, context: RunContext) -&gt; MyResult:\n        ...\n</code></pre> <p>The app contains only domain logic.</p>"},{"location":"projects/celine-digital-twin/docs/create-module/#4-implement-mappers","title":"4. Implement mappers","text":"<pre><code>class MyInputMapper(InputMapper[MyInputs]):\n    def map(self, raw: Mapping) -&gt; MyInputs:\n        ...\n\nclass MyOutputMapper(OutputMapper[MyResult]):\n    def map(self, obj: MyResult) -&gt; dict:\n        ...\n</code></pre> <p>Mappers define the external contract.</p>"},{"location":"projects/celine-digital-twin/docs/create-module/#5-register-the-module","title":"5. Register the module","text":"<pre><code>class MyModule:\n    name = \"my-module\"\n    version = \"1.0.0\"\n\n    def register(self, registry: DTRegistry) -&gt; None:\n        registry.register_app(\n            MyApp(),\n            input_mapper=MyInputMapper(),\n            output_mapper=MyOutputMapper(),\n        )\n\nmodule = MyModule()\n</code></pre>"},{"location":"projects/celine-digital-twin/docs/create-module/#6-enable-the-module","title":"6. Enable the module","text":"<p>Add the module to <code>config/modules.yaml</code>:</p> <pre><code>modules:\n  - name: my-module\n    import: celine.dt.modules.my_module.module:module\n    enabled: true\n</code></pre>"},{"location":"projects/celine-digital-twin/docs/create-module/#7-verify","title":"7. Verify","text":"<pre><code>curl http://localhost:8000/apps\ncurl http://localhost:8000/apps/my-app/describe\n</code></pre> <p>Your module is now part of the Digital Twin runtime.</p>"},{"location":"projects/celine-infra/","title":"CELINE Infrastructure (<code>infra</code>)","text":"<p>This repository contains the infrastructure-as-code used to deploy and operate the CELINE platform across local, staging, and production environments.</p> <p>It defines: - Kubernetes infrastructure - Helm / Helmfile-based deployments - Encrypted secrets handling - Environment-specific configuration</p> <p>The repository is operator-oriented and assumes familiarity with Kubernetes tooling.</p>"},{"location":"projects/celine-infra/#overview","title":"Overview","text":"<p>CELINE infrastructure follows a declarative and reproducible model based on:</p> <ul> <li>Helm charts as the primary deployment unit</li> <li>Helmfile to coordinate multiple Helm releases</li> <li>Helm plugins for diffing and secrets integration</li> <li>SOPS for encrypted configuration</li> <li>Task as a convenience wrapper for common operational commands</li> <li>Minikube for local development</li> </ul> <p>No imperative deployment scripts are used. Infrastructure is applied using Helmfile-driven workflows.</p>"},{"location":"projects/celine-infra/#repository-layout","title":"Repository Layout","text":"<pre><code>infra/\n\u251c\u2500\u2500 charts/           # CELINE and third-party Helm charts\n\u251c\u2500\u2500 envs/             # Environment bindings (symlinks)\n\u251c\u2500\u2500 defaults/         # Default configurations for charts\n\u251c\u2500\u2500 helmfile.d/       # helmfile catalogue of Helm charts\n\u2514\u2500\u2500 .sops.yaml/.sops  # SOPS-encrypted secrets\n</code></pre>"},{"location":"projects/celine-infra/#required-tooling-local-setup","title":"Required Tooling (Local Setup)","text":"<p>Local setup is mandatory. Install the following tools:</p> <ul> <li> <p><code>task</code>   https://taskfile.dev/docs/installation</p> </li> <li> <p><code>minikube</code>   https://minikube.sigs.k8s.io/docs/start</p> </li> <li> <p><code>kubectl</code>   https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/</p> </li> <li> <p><code>helm</code>   https://helm.sh/docs/intro/install/</p> </li> <li> <p><code>helm-diff</code> (required by Helmfile) <code>bash   helm plugin install https://github.com/databus23/helm-diff</code></p> </li> <li> <p><code>helm-secrets</code> (required by Helmfile) <code>bash   helm plugin install https://github.com/jkroepke/helm-secrets --version v4.7.4</code></p> </li> <li> <p><code>helmfile</code>   https://helmfile.readthedocs.io/en/latest/#installation</p> </li> <li> <p><code>skaffold</code>   https://skaffold.dev/docs/install/#standalone-binary</p> </li> </ul> <p>Missing any of the above will result in a broken setup.</p>"},{"location":"projects/celine-infra/#local-kubernetes-environment-minikube","title":"Local Kubernetes Environment (Minikube)","text":"<p>Start Minikube with sufficient resources:</p> <pre><code>minikube start --cpus=4 --memory=8192\n</code></pre> <p>Ensure your kube context is set correctly:</p> <pre><code>kubectl config use-context minikube\n</code></pre>"},{"location":"projects/celine-infra/#local-dns-configuration-celinelocal","title":"Local DNS Configuration (<code>*.celine.local</code>)","text":"<p>CELINE services rely on Ingress host-based routing.</p> <p>For local development, services are exposed under <code>*.celine.local</code>.</p> <p>Add the following entry to <code>/etc/hosts</code>:</p> <pre><code>192.168.49.2 dashboard.celine.local s3.celine.local keycloak.celine.local mqtt.celine.local sso.celine.local prefect.celine.local superset.celine.local s3.celine.local\n</code></pre> <p>Notes: - Replace <code>192.168.49.2</code> with the output of <code>minikube ip</code> if different - Hostnames must match ingress definitions - OAuth redirect URIs depend on these domains</p> <p>Using <code>localhost</code> will not work.</p>"},{"location":"projects/celine-infra/#secrets-management-sops","title":"Secrets Management (SOPS)","text":"<p>All secrets are stored encrypted at rest.</p> <p>Typical workflows:</p> <pre><code>sops -e secrets.yaml &gt; secrets.enc.yaml\nsops -d secrets.enc.yaml\n</code></pre> <p>Helmfile integrates with <code>helm-secrets</code> to decrypt secrets at deploy time.</p> <p>Plaintext secrets must never be committed.</p>"},{"location":"projects/celine-infra/#applying-infrastructure-helmfile","title":"Applying Infrastructure (Helmfile)","text":"<p>From the <code>infra/</code> directory:</p>"},{"location":"projects/celine-infra/#apply-an-environment","title":"Apply an environment","text":"<pre><code>helmfile -e dev apply\n</code></pre>"},{"location":"projects/celine-infra/#diff-changes-before-applying","title":"Diff changes before applying","text":"<pre><code>helmfile -e dev diff\n</code></pre>"},{"location":"projects/celine-infra/#destroy-an-environment","title":"Destroy an environment","text":"<pre><code>helmfile -e dev destroy\n</code></pre>"},{"location":"projects/celine-infra/#apply-a-single-release","title":"Apply a single release","text":"<pre><code>helmfile -e dev apply --selector name=&lt;release-name&gt;\n</code></pre>"},{"location":"projects/celine-infra/#operational-guidelines","title":"Operational Guidelines","text":"<ul> <li>Do not commit plaintext secrets</li> <li>Encrypt secrets before apply</li> <li>Prefer <code>helmfile diff</code> before <code>apply</code></li> <li>Avoid manual <code>helm install</code></li> <li>Keep environment changes isolated</li> <li>Production environments require additional safeguards</li> </ul>"},{"location":"projects/celine-infra/#intended-audience","title":"Intended Audience","text":"<p>This repository is intended for: - Infrastructure engineers - Platform operators - CI/CD automation</p> <p>It is not intended as a general developer quickstart.</p>"},{"location":"projects/celine-infra/#related-projects","title":"Related Projects","text":"<ul> <li>CELINE pipelines: https://github.com/celine-eu/celine-pipelines</li> <li>CELINE project: https://celineproject.eu/</li> <li>CELINE docs: https://celine-eu.github.io/</li> </ul>"},{"location":"projects/celine-pipelines/","title":"CELINE Pipelines","text":"<p>CELINE Pipelines is the reference repository providing production-ready, open-data\u2013based processing pipelines built on top of the CELINE data processing framework.</p> <p>Each pipeline is a self-contained, reproducible application that ingests, transforms, governs, and publishes datasets following CELINE standards for: - data layers (raw / staging / silver / gold) - governance &amp; licensing - OpenLineage metadata - container-first execution - cloud and on-prem deployments</p> <p>This repository is part of the CELINE EU project.</p> <p>\ud83c\udf0d Project website: https://celineproject.eu \ud83d\udee0 Open-source tools &amp; docs: https://celine-eu.github.io/</p>"},{"location":"projects/celine-pipelines/#what-this-repository-contains","title":"What this repository contains","text":"<p>This repository hosts end-to-end data pipelines based on open and public data sources, including:</p> <ul> <li>Meteorological data</li> <li>OpenWeatherMap (OWM)</li> <li>Deutscher Wetterdienst (DWD \u2013 ICON-D2)</li> <li>Copernicus Climate &amp; Atmosphere Services (ERA5, CAMS)</li> <li>Geospatial open data</li> <li>OpenStreetMap (OSM)</li> </ul> <p>Each pipeline follows the same canonical CELINE structure: - ingestion (Meltano / Singer taps) - transformations (dbt: staging \u2192 silver \u2192 gold) - orchestration (Prefect) - governance metadata (<code>governance.yaml</code>) - containerized execution (Docker / Skaffold)</p>"},{"location":"projects/celine-pipelines/#repository-structure","title":"Repository structure","text":"<pre><code>celine-pipelines/\n\u251c\u2500\u2500 apps/\n\u2502   \u251c\u2500\u2500 copernicus/     # Copernicus Climate &amp; Atmosphere pipelines\n\u2502   \u251c\u2500\u2500 dwd/            # DWD ICON-D2 weather model\n\u2502   \u251c\u2500\u2500 osm/            # OpenStreetMap ingestion &amp; curation\n\u2502   \u2514\u2500\u2500 owm/            # OpenWeatherMap pipelines\n\u2502\n\u251c\u2500\u2500 scripts/            # Release &amp; utility scripts\n\u251c\u2500\u2500 skaffold.yaml       # Container build configuration\n\u251c\u2500\u2500 taskfile.yaml       # Developer &amp; CI tasks\n\u251c\u2500\u2500 pyproject.toml\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Each subfolder under <code>apps/</code> is a fully independent pipeline application with its own: - Prefect flows - dbt project - Meltano configuration - governance rules - versioning</p>"},{"location":"projects/celine-pipelines/#pipeline-architecture-celine-standard","title":"Pipeline architecture (CELINE standard)","text":"<p>All pipelines implement the same layered data model:</p> Layer Purpose RAW Verbatim ingested data STAGING Technical normalization SILVER Enriched, curated datasets GOLD Shareable, domain-ready datasets <p>Governance rules (license, access level, attribution, retention) are declared explicitly per dataset in <code>governance.yaml</code>.</p>"},{"location":"projects/celine-pipelines/#adding-a-new-pipeline","title":"Adding a new pipeline","text":"<p>To create and integrate a new pipeline, follow the official tutorial:</p> <p>\ud83d\udc49 Pipeline integration tutorial https://celine-eu.github.io/projects/celine-utils/docs/pipeline-tutorial/</p> <p>The tutorial covers: - creating a new pipeline skeleton - defining Prefect flows - configuring Meltano &amp; dbt - adding governance metadata - local development and container execution</p> <p>All pipelines in this repository are built following that guide.</p>"},{"location":"projects/celine-pipelines/#local-development","title":"Local development","text":""},{"location":"projects/celine-pipelines/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python \u2265 3.11</li> <li>Docker &amp; Docker Compose</li> <li><code>uv</code> </li> <li>Prefect</li> </ul>"},{"location":"projects/celine-pipelines/#setup","title":"Setup","text":"<pre><code>task setup\n</code></pre>"},{"location":"projects/celine-pipelines/#run-a-pipeline","title":"Run a pipeline","text":"<p>Example (OpenWeatherMap):</p> <pre><code>task pipeline:owm:run\n</code></pre>"},{"location":"projects/celine-pipelines/#versioning-releases","title":"Versioning &amp; releases","text":"<p>Each pipeline is versioned independently.</p> <p>Example:</p> <pre><code>task pipeline:osm:release\n</code></pre>"},{"location":"projects/celine-pipelines/#governance-licensing","title":"Governance &amp; licensing","text":"<p>All datasets are governed explicitly: - licenses are respected and propagated - attribution is enforced - access levels are declared (<code>internal</code>, <code>external</code>, <code>restricted</code>) - ingestion artifacts are never exposed</p> <p>See each pipeline\u2019s <code>governance.yaml</code> for authoritative rules.</p>"},{"location":"projects/celine-pipelines/#related-repositories","title":"Related repositories","text":"<ul> <li>celine-utils \u2013 shared pipeline framework   https://github.com/celine-eu/celine-utils</li> <li>CELINE documentation portal   https://celine-eu.github.io/</li> </ul>"},{"location":"projects/celine-pipelines/#license","title":"License","text":"<p>Copyright &gt;=2025 Spindox Labs</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0</p> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"projects/celine-pipelines/#acknowledgements","title":"Acknowledgements","text":"<p>This work is part of the CELINE project, funded under the European Union framework, and builds upon multiple open data initiatives including: - Copernicus Programme - Deutscher Wetterdienst (DWD) - OpenStreetMap contributors - OpenWeather Ltd.</p>"},{"location":"projects/celine-pipelines/apps/copernicus/","title":"Copernicus Pipeline","text":""},{"location":"projects/celine-pipelines/apps/copernicus/#overview","title":"Overview","text":"<p>The Copernicus pipeline ingests and processes climate and atmospheric datasets from the Copernicus Climate Change Service (C3S) and Copernicus Atmosphere Monitoring Service (CAMS).</p> <p>It focuses on ERA5 reanalysis and CAMS solar radiation and air quality datasets, transforming raw GRIB/CSV files into curated datasets suitable for analytics and downstream CELINE applications.</p>"},{"location":"projects/celine-pipelines/apps/copernicus/#data-sources","title":"Data sources","text":"<ul> <li>ERA5 single-level reanalysis (daily &amp; monthly)</li> <li>CAMS global reanalysis (monthly)</li> <li>CAMS solar radiation time series</li> </ul> <p>All datasets are retrieved using official Copernicus APIs.</p>"},{"location":"projects/celine-pipelines/apps/copernicus/#output-datasets","title":"Output datasets","text":"<p>The pipeline exports:</p> <ul> <li>RAW</li> <li>Verbatim ERA5 and CAMS datasets</li> <li>STAGING</li> <li>Normalized meteorological variables</li> <li>SILVER</li> <li>Curated, analysis-ready climate indicators</li> <li>GOLD</li> <li>Domain-specific aggregates (where applicable)</li> </ul> <p>Dataset governance, licensing, and attribution are defined in <code>governance.yaml</code>.</p>"},{"location":"projects/celine-pipelines/apps/copernicus/#execution-docker-image","title":"Execution &amp; Docker image","text":"<p>Docker image:</p> <pre><code>ghcr.io/celine-eu/pipeline-copernicus\n</code></pre> <p>Run locally:</p> <pre><code>task pipeline:copernicus:run\n</code></pre>"},{"location":"projects/celine-pipelines/apps/copernicus/#configuration-overrides","title":"Configuration &amp; overrides","text":"<p>Custom deployments can override: - CDS / ADS API keys - Spatial bounding boxes - Temporal ranges - Storage backend (local FS or S3)</p> <p>See: - <code>flows/cds_config.yaml</code> - environment variables in <code>.env.example</code></p>"},{"location":"projects/celine-pipelines/apps/copernicus/#contributing","title":"Contributing","text":"<p>To propose changes: 1. Fork the repository 2. Modify configs, dbt models, or Prefect flows 3. Update governance if datasets change 4. Submit a pull request with documentation</p>"},{"location":"projects/celine-pipelines/apps/dwd/","title":"DWD Pipeline","text":""},{"location":"projects/celine-pipelines/apps/dwd/#overview","title":"Overview","text":"<p>The DWD pipeline processes numerical weather prediction data from the Deutscher Wetterdienst (DWD), specifically the ICON-D2 high-resolution model.</p> <p>It is designed for near-real-time weather forecasting and risk assessment use cases.</p>"},{"location":"projects/celine-pipelines/apps/dwd/#data-sources","title":"Data sources","text":"<ul> <li>ICON-D2 forecast model (open data)</li> </ul> <p>Data is downloaded from: https://opendata.dwd.de/</p>"},{"location":"projects/celine-pipelines/apps/dwd/#output-datasets","title":"Output datasets","text":"<ul> <li>RAW</li> <li>Full ICON-D2 GRIB forecasts</li> <li>STAGING</li> <li>Parsed meteorological variables</li> <li>SILVER</li> <li>Enriched wind and gust datasets</li> <li>GOLD</li> <li>Shareable weather indicators (e.g. gust alerts)</li> </ul> <p>Licensing follows <code>dl-de/by-2-0</code>.</p>"},{"location":"projects/celine-pipelines/apps/dwd/#execution-docker-image","title":"Execution &amp; Docker image","text":"<p>Docker image:</p> <pre><code>ghcr.io/celine-eu/pipeline-dwd\n</code></pre> <p>Run locally:</p> <pre><code>task pipeline:dwd:run\n</code></pre>"},{"location":"projects/celine-pipelines/apps/dwd/#configuration-overrides","title":"Configuration &amp; overrides","text":"<p>Customizable options: - Geographic bounding boxes - Forecast steps &amp; variables - Retention and cleanup policies</p> <p>See: - <code>flows/config.yaml</code> - dbt cleanup operations</p>"},{"location":"projects/celine-pipelines/apps/dwd/#contributing","title":"Contributing","text":"<p>Contributions may include: - additional ICON products - new derived indicators - improved cleanup or validation logic</p> <p>Ensure: - licensing remains compatible - derived datasets are documented in governance</p>"},{"location":"projects/celine-pipelines/apps/osm/","title":"OpenStreetMap Pipeline","text":""},{"location":"projects/celine-pipelines/apps/osm/#overview","title":"Overview","text":"<p>The OSM pipeline ingests and curates OpenStreetMap geospatial data for selected regions, producing thematic datasets for mobility, tourism, infrastructure, and services.</p>"},{"location":"projects/celine-pipelines/apps/osm/#data-sources","title":"Data sources","text":"<ul> <li>OpenStreetMap planet extracts</li> <li>Regional queries via Overpass-compatible tooling</li> </ul> <p>License: ODbL 1.0</p>"},{"location":"projects/celine-pipelines/apps/osm/#output-datasets","title":"Output datasets","text":"<ul> <li>RAW</li> <li>GeoJSON extracts</li> <li>STAGING</li> <li>Normalized geometries</li> <li>SILVER</li> <li>Thematic layers (parking, hospitality, EV charging, etc.)</li> <li>GOLD</li> <li>Externally shareable geospatial datasets</li> </ul> <p>Attribution is mandatory and enforced.</p>"},{"location":"projects/celine-pipelines/apps/osm/#execution-docker-image","title":"Execution &amp; Docker image","text":"<p>Docker image:</p> <pre><code>ghcr.io/celine-eu/pipeline-osm\n</code></pre> <p>Run locally:</p> <pre><code>task pipeline:osm:run\n</code></pre>"},{"location":"projects/celine-pipelines/apps/osm/#configuration-overrides","title":"Configuration &amp; overrides","text":"<p>Custom use cases can adjust: - Areas of interest - OSM tag filters - Output formats</p> <p>See: - <code>flows/osm_config.yaml</code></p>"},{"location":"projects/celine-pipelines/apps/osm/#contributing","title":"Contributing","text":"<p>New contributions should: - respect ODbL requirements - preserve attribution - document new thematic layers</p> <p>Do not open PRs adding new regions, override <code>flows/osm_config.yaml</code> to adapt to your needs instead.</p>"},{"location":"projects/celine-pipelines/apps/owm/","title":"OpenWeatherMap Pipeline","text":""},{"location":"projects/celine-pipelines/apps/owm/#overview","title":"Overview","text":"<p>The OpenWeatherMap pipeline ingests weather observations and forecasts using the OpenWeatherMap One Call API and produces curated weather datasets.</p> <p>It supports multiple locations and time resolutions.</p>"},{"location":"projects/celine-pipelines/apps/owm/#data-sources","title":"Data sources","text":"<ul> <li>OpenWeatherMap One Call API 3.0</li> </ul> <p>License constraints apply (non-commercial sharing).</p>"},{"location":"projects/celine-pipelines/apps/owm/#output-datasets","title":"Output datasets","text":"<ul> <li>RAW</li> <li>API responses</li> <li>STAGING</li> <li>Normalized time series</li> <li>SILVER</li> <li>Internal analytical datasets</li> <li>GOLD</li> <li>Shareable aggregated weather indicators</li> </ul> <p>Licensing is enforced per dataset.</p>"},{"location":"projects/celine-pipelines/apps/owm/#execution-docker-image","title":"Execution &amp; Docker image","text":"<p>Docker image:</p> <pre><code>ghcr.io/celine-eu/pipeline-owm\n</code></pre> <p>Run locally:</p> <pre><code>task pipeline:owm:run\n</code></pre>"},{"location":"projects/celine-pipelines/apps/owm/#configuration-overrides","title":"Configuration &amp; overrides","text":"<p>Customizable options: - Locations (lat/lon or city) - Update frequency - Units and aggregation logic</p> <p>Configured via: - Meltano configs - Environment variables</p>"},{"location":"projects/celine-pipelines/apps/owm/#contributing","title":"Contributing","text":"<p>Due to API license constraints: - no raw data redistribution - derived datasets only</p> <p>Contributions should focus on: - transformations - indicators - metadata improvements</p>"},{"location":"projects/celine-utils/","title":"CELINE Utils","text":"<p>CELINE Utils is a collection of shared utilities, libraries, and command-line tools that form the technical backbone of the CELINE data platform.</p> <p>It provides reusable building blocks for data pipelines, governance, lineage, metadata management, and platform integrations. The repository is designed to be embedded into CELINE applications and executed within orchestrated environments using Meltano, dbt, Prefect, and OpenLineage.</p>"},{"location":"projects/celine-utils/#scope-and-goals","title":"Scope and Goals","text":"<p>The goals of this repository are to:</p> <ul> <li>Centralize cross-cutting platform logic used by multiple CELINE projects</li> <li>Provide opinionated but extensible tooling for data pipelines</li> <li>Enforce consistent governance and lineage semantics</li> <li>Reduce duplication across pipeline applications</li> <li>Act as a stable foundation for CELINE-compatible services and workflows</li> </ul> <p>This is not an end-user application; it is a platform utility layer.</p>"},{"location":"projects/celine-utils/#key-capabilities","title":"Key Capabilities","text":""},{"location":"projects/celine-utils/#command-line-interface-cli","title":"Command Line Interface (CLI)","text":"<p>A unified CLI built with Typer exposes administrative, governance, and pipeline utilities:</p> <pre><code>celine-utils\n \u251c\u2500\u2500 governance\n \u2502    \u2514\u2500\u2500 generate\n \u2514\u2500\u2500 pipeline\n      \u251c\u2500\u2500 init\n      \u2514\u2500\u2500 run\n</code></pre>"},{"location":"projects/celine-utils/#pipeline-orchestration","title":"Pipeline Orchestration","text":"<p>CELINE Utils provides a structured execution layer for:</p> <ul> <li>Meltano ingestion pipelines</li> <li>dbt transformations and tests</li> <li>Prefect-based Python flows</li> </ul> <p>The <code>PipelineRunner</code> coordinates execution, logging, error handling, and lineage emission in a consistent way across tools.</p> <p>See the pipeline tutorial to discover how to setup and deploy a new pipeline.</p>"},{"location":"projects/celine-utils/#openlineage-integration","title":"OpenLineage Integration","text":"<p>First-class OpenLineage support includes:</p> <ul> <li>Automatic emission of START, COMPLETE, FAIL, and ABORT events</li> <li>Dataset-level schema facets</li> <li>Data quality assertions from dbt tests</li> <li>Custom CELINE governance facets</li> </ul>"},{"location":"projects/celine-utils/#governance-framework","title":"Governance Framework","text":"<p>A declarative <code>governance.yaml</code> specification allows you to define:</p> <ul> <li>Dataset ownership</li> <li>License and access level</li> <li>Classification and retention</li> <li>Tags and documentation links</li> </ul> <p>Governance rules are resolved using pattern matching and injected into lineage events.</p>"},{"location":"projects/celine-utils/#dataset-tooling","title":"Dataset Tooling","text":"<p>The <code>DatasetClient</code> enables:</p> <ul> <li>Schema and table introspection</li> <li>Column metadata inspection</li> <li>Safe query construction</li> <li>Export to Pandas</li> </ul>"},{"location":"projects/celine-utils/#platform-integrations","title":"Platform Integrations","text":"<p>Built-in integrations include:</p> <ul> <li>Keycloak for identity and access management</li> <li>Apache Superset for analytics platform integration</li> <li>MQTT for lightweight messaging</li> </ul>"},{"location":"projects/celine-utils/#repository-structure","title":"Repository Structure","text":"<pre><code>celine/\n  admin/\n  cli/\n  common/\n  datasets/\n  pipelines/\nschemas/\ntests/\n</code></pre>"},{"location":"projects/celine-utils/#configuration","title":"Configuration","text":"<p>Configuration is environment-driven using <code>pydantic-settings</code>:</p> <ul> <li>Environment variables first</li> <li>Optional <code>.env</code> files</li> <li>Typed validation</li> <li>Container-friendly defaults</li> </ul>"},{"location":"projects/celine-utils/#installation","title":"Installation","text":"<pre><code>pip install celine-utils\n</code></pre>"},{"location":"projects/celine-utils/#intended-audience","title":"Intended Audience","text":"<p>CELINE Utils is intended for:</p> <ul> <li>Data engineers</li> <li>Platform engineers</li> <li>CELINE application developers</li> </ul> <p>It is not a general-purpose data tooling library.</p>"},{"location":"projects/celine-utils/#license","title":"License","text":"<p>Copyright \u00a9 2025 Spindox Labs</p> <p>Licensed under the Apache License, Version 2.0.</p>"},{"location":"projects/celine-utils/docs/governance/","title":"Dataset Governance","text":"<p>This document describes how dataset governance is defined, configured, and applied in CELINE pipelines using the <code>governance.yaml</code> file and the CELINE CLI.</p> <p>Governance metadata is used to enrich OpenLineage events, provide a single source of truth for licensing, attribution, ownership, access intent, and data sensitivity, and to enable future integration with dataspace and contract-based access models.</p>"},{"location":"projects/celine-utils/docs/governance/#what-is-governanceyaml","title":"What Is <code>governance.yaml</code>","text":"<p><code>governance.yaml</code> is a declarative configuration file that defines governance rules for datasets produced or consumed by a pipeline.</p> <p>It allows you to specify, per dataset or dataset pattern:</p> <ul> <li>License</li> <li>Attribution (mandatory where required by license)</li> <li>Ownership</li> <li>Access level (exposure intent)</li> <li>Access requirements (preconditions such as contracts or partnerships)</li> <li>Classification / sensitivity</li> <li>Tags</li> <li>Retention policy</li> <li>Documentation and source system</li> </ul> <p>These rules are resolved at runtime and injected into lineage events as custom OpenLineage dataset facets.</p>"},{"location":"projects/celine-utils/docs/governance/#where-the-file-lives","title":"Where the File Lives","text":"<p>For a pipeline application named <code>&lt;app_name&gt;</code>, the expected location is:</p> <pre><code>PIPELINES_ROOT/\n\u2514\u2500\u2500 apps/\n    \u2514\u2500\u2500 &lt;app_name&gt;/\n        \u2514\u2500\u2500 governance.yaml\n</code></pre> <p>The file is automatically discovered by CELINE tooling at runtime.</p> <p>You can override discovery using:</p> <pre><code>GOVERNANCE_CONFIG_PATH=/absolute/path/to/governance.yaml\n</code></pre>"},{"location":"projects/celine-utils/docs/governance/#file-structure","title":"File Structure","text":"<p>A <code>governance.yaml</code> file has two top-level sections:</p> <ul> <li><code>defaults</code>: applied to all datasets unless overridden</li> <li><code>sources</code>: dataset-specific or pattern-based rules</li> </ul>"},{"location":"projects/celine-utils/docs/governance/#example-governanceyaml","title":"Example <code>governance.yaml</code>","text":"<pre><code>defaults:\n  license: null\n  attribution: null\n  ownership: []\n  access_level: internal\n  access_requirements: partner\n  classification: green\n  tags: []\n  retention_days: 365\n  documentation_url: https://example.com/datasets/docs\n  source_system: \"integration-tests\"\n\nsources:\n  datasets.ds.gold.weather_hourly:\n    license: CC-BY-NC-4.0\n    attribution: &gt;\n      Weather data derived from OpenWeatherMap One Call API 3.0 \u00a9 OpenWeather Ltd.\n    ownership:\n      - name: Weather Team\n        type: DATA_OWNER\n    access_level: restricted\n    access_requirements: contract\n    classification: green\n    tags: [gold, weather]\n\n  datasets.ds.raw.weather_events:\n    license: proprietary\n    ownership:\n      - name: Internal Platform\n        type: DATA_OWNER\n    access_level: restricted\n    classification: pii\n    tags: [raw, sensitive]\n</code></pre>"},{"location":"projects/celine-utils/docs/governance/#defaults-section","title":"Defaults Section","text":"<p>The <code>defaults</code> block defines baseline governance applied to all datasets unless overridden.</p> <p>Typical use cases: - Global access level - Default access requirements - Retention policy - Shared documentation URL - Default classification</p> <p>Fields set to <code>null</code> are omitted unless overridden.</p>"},{"location":"projects/celine-utils/docs/governance/#sources-section","title":"Sources Section","text":"<p>The <code>sources</code> section defines governance rules for specific datasets or patterns.</p>"},{"location":"projects/celine-utils/docs/governance/#dataset-keys","title":"Dataset Keys","text":"<p>Keys correspond to OpenLineage dataset names, for example:</p> <ul> <li><code>database.schema.table</code></li> <li><code>datasets.ds.gold.weather_hourly</code></li> <li><code>singer.tap-openweathermap.forecast_stream</code></li> </ul>"},{"location":"projects/celine-utils/docs/governance/#pattern-matching","title":"Pattern Matching","text":"<p>Wildcard rules are supported using glob semantics:</p> <pre><code>sources:\n  datasets.ds.*:\n    access_level: internal\n\n  datasets.raw.*:\n    classification: red\n</code></pre> <p>Resolution precedence: 1. Exact match 2. Longest matching wildcard 3. Defaults</p>"},{"location":"projects/celine-utils/docs/governance/#governance-fields","title":"Governance Fields","text":""},{"location":"projects/celine-utils/docs/governance/#license","title":"<code>license</code>","text":"<p>License identifier for the dataset (e.g. <code>CC-BY-NC-4.0</code>, <code>ODbL-1.0</code>, <code>proprietary</code>).</p>"},{"location":"projects/celine-utils/docs/governance/#attribution","title":"<code>attribution</code>","text":"<p>Mandatory attribution text required by the dataset license. This text should be surfaced in catalogs, APIs, or documentation when datasets are exposed.</p>"},{"location":"projects/celine-utils/docs/governance/#ownership","title":"<code>ownership</code>","text":"<p>List of owners responsible for the dataset.</p> <pre><code>ownership:\n  - name: Data Platform Team\n    type: DATA_OWNER\n</code></pre>"},{"location":"projects/celine-utils/docs/governance/#access_level","title":"<code>access_level</code>","text":"<p>Defines the intended exposure level of the dataset.</p> <p>Allowed values: - <code>open</code> \u2014 publicly shareable - <code>internal</code> \u2014 organization-wide access - <code>restricted</code> \u2014 limited, explicitly authorized access</p> <p>Access level expresses intent, not enforcement.</p>"},{"location":"projects/celine-utils/docs/governance/#access_requirements","title":"<code>access_requirements</code>","text":"<p>Defines preconditions that must be satisfied before access can be granted.</p> <p>Allowed values: - <code>all</code> \u2014 no precondition - <code>partner</code> \u2014 ecosystem or organizational partner - <code>contract</code> \u2014 explicit legal or data-sharing agreement</p> <p>This field is designed to integrate with dataspace and contract-based models without binding to IAM or policy engines.</p>"},{"location":"projects/celine-utils/docs/governance/#classification","title":"<code>classification</code>","text":"<p>Describes the intrinsic sensitivity of the data.</p> <p>Allowed values: - <code>green</code> \u2014 non-sensitive - <code>yellow</code> \u2014 potentially sensitive - <code>red</code> \u2014 sensitive or regulated - <code>pii</code> \u2014 personal data</p> <p>Classification does not grant or deny access; it informs compliance and handling requirements.</p>"},{"location":"projects/celine-utils/docs/governance/#tags","title":"<code>tags</code>","text":"<p>Free-form labels used for discovery, grouping, or filtering.</p>"},{"location":"projects/celine-utils/docs/governance/#retention_days","title":"<code>retention_days</code>","text":"<p>Retention period in days.</p>"},{"location":"projects/celine-utils/docs/governance/#documentation_url","title":"<code>documentation_url</code>","text":"<p>Link to human-readable documentation for the dataset.</p>"},{"location":"projects/celine-utils/docs/governance/#source_system","title":"<code>source_system</code>","text":"<p>Origin system or domain (e.g. <code>openweathermap</code>, <code>copernicus</code>, <code>dwd</code>).</p>"},{"location":"projects/celine-utils/docs/governance/#how-governance-is-applied","title":"How Governance Is Applied","text":"<p>During pipeline execution:</p> <ol> <li>Dataset lineage is collected</li> <li>Dataset names are resolved against <code>governance.yaml</code></li> <li>Defaults and overrides are merged</li> <li>Governance metadata is emitted as a custom OpenLineage dataset facet</li> </ol> <p>This applies to: - Inputs - Outputs - dbt test datasets</p>"},{"location":"projects/celine-utils/docs/governance/#openlineage-integration","title":"OpenLineage Integration","text":"<p>Governance metadata is published as a custom GovernanceDatasetFacet, including:</p> <ul> <li>License</li> <li>Attribution</li> <li>Access level</li> <li>Access requirements</li> <li>Classification</li> <li>Retention</li> <li>Source system</li> </ul> <p>This allows downstream systems (catalogs, dataspaces, policy engines) to reason about datasets consistently.</p>"},{"location":"projects/celine-utils/docs/governance/#interactive-cli-usage","title":"Interactive CLI Usage","text":"<p>CELINE provides an interactive CLI to generate governance files.</p>"},{"location":"projects/celine-utils/docs/governance/#command","title":"Command","text":"<pre><code>celine-utils governance generate marquez --app &lt;app_name&gt;\n</code></pre> <p>The CLI will: 1. Discover datasets from Marquez 2. Prompt for governance metadata per dataset 3. Allow pattern-based scoping 4. Write <code>governance.yaml</code> to the pipeline folder</p>"},{"location":"projects/celine-utils/docs/governance/#non-interactive-mode","title":"Non-Interactive Mode","text":"<pre><code>celine-utils governance generate marquez --app &lt;app_name&gt; --yes\n</code></pre> <p>Generates a skeleton file using defaults.</p>"},{"location":"projects/celine-utils/docs/governance/#best-practices","title":"Best Practices","text":"<ul> <li>Use defaults to minimize repetition</li> <li>Prefer wildcard rules for schema-level governance</li> <li>Keep dataset names stable</li> <li>Version governance files with code</li> <li>Treat governance as declarative metadata, not enforcement logic</li> </ul>"},{"location":"projects/celine-utils/docs/governance/#summary","title":"Summary","text":"<p><code>governance.yaml</code> provides a single, declarative mechanism for defining dataset governance in CELINE pipelines.</p> <p>It is: - Pattern-based - License- and attribution-aware - Dataspace-ready - Integrated with lineage - CLI-assisted</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/","title":"CELINE Pipelines Tutorial","text":"<p>This document provides a complete, end-to-end guide to setting up, running, and deploying a CELINE pipeline application. It consolidates all prior sections into a single reference file.</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#overview","title":"Overview","text":"<p>A CELINE pipeline is a self-contained application that combines:</p> <ul> <li>Meltano (ingestion / bronze)</li> <li>dbt (staging, silver, gold)</li> <li>Optional Python / Prefect flows</li> <li>Governance configuration</li> <li>OpenLineage emission (optional)</li> <li>Container-first execution</li> </ul> <p>Pipelines are designed to run identically in: - Local development - CI - Kubernetes</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#creating-a-new-pipeline-application","title":"Creating a New Pipeline Application","text":"<p>CELINE provides a CLI command to scaffold a complete pipeline application with sane defaults.</p> <p>From the root of your pipelines repository:</p> <pre><code>celine-utils pipeline init app demo_app\n</code></pre> <p>This command creates a fully functional example pipeline with:</p> <ul> <li>Meltano project</li> <li>dbt project structure</li> <li>Example Prefect-compatible flow</li> <li>Governance configuration</li> <li><code>.env</code> file</li> <li>README</li> </ul> <p>You can safely use the generated structure as-is and evolve it incrementally.</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#canonical-repository-layout","title":"Canonical Repository Layout","text":"<p>After initialization, your repository will look like:</p> <pre><code>pipelines/\n\u2514\u2500\u2500 apps/\n    \u2514\u2500\u2500 demo_app/\n        \u251c\u2500\u2500 meltano/\n        \u251c\u2500\u2500 dbt/\n        \u251c\u2500\u2500 flows/\n        \u251c\u2500\u2500 governance.yaml\n        \u251c\u2500\u2500 .env\n        \u2514\u2500\u2500 README.md\n</code></pre> <p>Each folder under <code>apps/</code> represents a deployable pipeline application.</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#baseline-docker-image-required","title":"Baseline Docker Image (Required)","text":"<p>All CELINE pipelines must be built on top of the official pipeline image:</p> <pre><code>ghcr.io/celine-eu/pipeline\n</code></pre> <p>This image already contains: - Python + uv - <code>celine-utils</code> - Meltano - dbt - Prefect - OpenLineage client</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#canonical-dockerfile-per-app","title":"Canonical Dockerfile (Per App)","text":"<p>Example Dockerfile for the <code>demo_app</code> pipeline:</p> <pre><code>ARG BASE_TAG=latest\nFROM ghcr.io/celine-eu/pipeline:${BASE_TAG}\n\nARG APP_NAME\n\nENV APP_NAME=${APP_NAME}\n\n# Enable / disable OpenLineage support\nENV OPENLINEAGE_ENABLED=false\nENV OPENLINEAGE_URL=http://marquez-api:5001\nENV OPENLINEAGE_NAMESPACE=${APP_NAME}\n\nENV PIPELINES_ROOT=${PIPELINES_ROOT:-/pipelines}\nENV BASE_DIR=\"${PIPELINES_ROOT}/apps\"\nENV APP_PATH=\"${BASE_DIR}/${APP_NAME}\"\n\nENV MELTANO_PROJECT_ROOT=\"${APP_PATH}/meltano\"\nENV DBT_PROJECT_DIR=\"${APP_PATH}/dbt\"\nENV DBT_PROFILES_DIR=\"${DBT_PROJECT_DIR}\"\n\nWORKDIR /pipelines\n\nCOPY ./apps/${APP_NAME} /pipelines/apps/${APP_NAME}\n\nRUN uv sync\n\nRUN if [ -f \"${APP_PATH}/requirements.txt\" ]; then       uv add --requirements \"${APP_PATH}/requirements.txt\";     fi\n\nRUN if [ -d \"${MELTANO_PROJECT_ROOT}\" ]; then       cd \"${MELTANO_PROJECT_ROOT}\" &amp;&amp;       rm -rf .meltano &amp;&amp;       MELTANO_PROJECT_ROOT=$(pwd) meltano install ;     fi\n\nRUN if [ -d \"${DBT_PROJECT_DIR}\" ]; then       cd \"${DBT_PROJECT_DIR}\" &amp;&amp;       rm -rf target dbt_packages .dbt &amp;&amp;       DBT_PROFILES_DIR=$(pwd) dbt deps ;     fi\n\nWORKDIR ${APP_PATH}\n</code></pre>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#build-example","title":"Build Example","text":"<pre><code>docker build   --build-arg APP_NAME=demo_app   -t demo-app-pipeline:latest   .\n</code></pre>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#environment-configuration","title":"Environment Configuration","text":"<p>CELINE uses environment-driven configuration.</p> <p>Minimal <code>.env</code>:</p> <pre><code>APP_NAME=demo_app\n\nPOSTGRES_HOST=postgres\nPOSTGRES_PORT=5432\nPOSTGRES_DB=datasets\nPOSTGRES_USER=postgres\nPOSTGRES_PASSWORD=postgres\n\nOPENLINEAGE_URL=http://marquez-api:5000\n</code></pre> <p>Resolution order: - Environment variables - <code>.env</code> files - Defaults</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#meltano-ingestion-bronze","title":"Meltano (Ingestion / Bronze)","text":"<p>Configure ingestion in <code>meltano/meltano.yml</code>.</p> <p>Example job:</p> <pre><code>jobs:\n  - name: import\n    tasks:\n      - tap-my-source target-postgres\n</code></pre> <p>Run manually:</p> <pre><code>celine-utils pipeline run meltano \"run import\"\n</code></pre> <p>CELINE automatically: - Executes Meltano - Discovers datasets - Emits lineage events (if enabled) - Applies governance metadata</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#dbt-staging-silver-gold","title":"dbt (Staging / Silver / Gold)","text":"<p>CELINE follows a medallion-style convention:</p> Layer Command Staging <code>celine-utils pipeline run dbt staging</code> Silver <code>celine-utils pipeline run dbt silver</code> Gold <code>celine-utils pipeline run dbt gold</code> Tests <code>celine-utils pipeline run dbt test</code> <p>During execution, CELINE:</p> <ul> <li>Collects schema metadata</li> <li>Captures dbt test results</li> <li>Emits dataset-level lineage</li> </ul>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#governance-configuration","title":"Governance Configuration","text":"<p>Each pipeline includes a <code>governance.yaml</code>.</p> <p>Example:</p> <pre><code>defaults:\n  access_level: internal\n  classification: green\n  retention_days: 365\n\nsources:\n  datasets.ds.gold_*:\n    license: CC0-1.0\n    ownership:\n      - name: data-team\n        type: DATA_OWNER\n    tags: [gold]\n</code></pre> <p>Governance is:</p> <ul> <li>Pattern-based</li> <li>Automatically resolved</li> <li>Emitted as a custom OpenLineage facet</li> </ul> <p>Generate interactively:</p> <pre><code>celine-utils governance generate marquez --app demo_app\n</code></pre> <p>Note Since governance are openlineage facets, disabling openlineage using <code>OPENLINEAGE_ENABLED=false</code> will exclude the governance tracking capabilities.</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#python-prefect-flows","title":"Python / Prefect Flows","text":"<p>Example <code>flows/pipeline.py</code>:</p> <pre><code>from prefect import flow\nfrom celine.utils.pipelines.pipeline import (\n    meltano_run_import,\n    dbt_run_staging,\n    dbt_run_silver,\n    dbt_run_gold,\n)\n\n@flow\ndef medallion_flow():\n    meltano_run_import()\n    dbt_run_staging()\n    dbt_run_silver()\n    dbt_run_gold()\n</code></pre>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#local-prefect-setup","title":"Local Prefect Setup","text":"<p>Start a local Prefect server:</p> <pre><code>prefect server start\n</code></pre> <p>Set API URL:</p> <pre><code>export PREFECT_API_URL=http://127.0.0.1:4200/api\n</code></pre>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#example-prefectyaml-local","title":"Example <code>prefect.yaml</code> (Local)","text":"<pre><code>name: demo-app\ndeployments:\n  - name: demo-app-flow\n    description: \"Demo app medallion pipeline\"\n    entrypoint: flows/pipeline.py:medallion_flow\n\n    schedule:\n      cron: \"0 * * * *\"\n\n    work_pool:\n      name: local-process\n      job_variables:\n        env:\n          APP_NAME: demo_app\n          PIPELINES_ROOT: /pipelines\n          POSTGRES_HOST: localhost\n          POSTGRES_DB: datasets\n</code></pre> <p>Register the deployment:</p> <pre><code>prefect deploy --prefect-file prefect.yaml\n</code></pre> <p>Run it:</p> <pre><code>prefect deployment run demo-app/demo-app-flow\n</code></pre>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#kubernetes-production-deployment","title":"Kubernetes &amp; Production Deployment","text":"<p>In Kubernetes, Prefect deployments are registered once and executed later by workers.</p> <p>CELINE provides a reference infrastructure repository at https://github.com/celine-eu/infra </p> <p>It includes:</p> <ul> <li>Prefect Server</li> <li>Prefect Workers</li> <li>Marquez / OpenLineage</li> <li>PostgreSQL</li> <li>Keycloak</li> <li>Helm charts</li> <li>Minikube-based local setup</li> <li>Other CELINE specific services, that can be omitted customizing the helmfiles</li> </ul>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#local-kubernetes-minikube","title":"Local Kubernetes (Minikube)","text":"<pre><code>minikube start\nkubectl create namespace celine\n</code></pre> <p>Follow the infra repository README to deploy the full stack.</p>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#recommended-workflow","title":"Recommended Workflow","text":"Stage Tool Local development Prefect local server Image build <code>ghcr.io/celine-eu/pipeline</code> Flow authoring <code>flows/*.py</code> Deployment config <code>prefect.yaml</code> Local execution <code>local-process</code> work pool Production CELINE infra Helm charts"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Use <code>celine-utils pipeline init</code> to bootstrap pipelines</li> <li>One Docker image per pipeline app</li> <li>Always use <code>ghcr.io/celine-eu/pipeline</code></li> <li>Governance is declarative and automatic</li> <li>Prefect deployments are configuration, not code</li> <li>Use CELINE infra for production</li> </ul>"},{"location":"projects/celine-utils/docs/pipeline-tutorial/#need-help","title":"Need help?","text":"<p>Open an issue or submit a pull request to propose improvements. Commercial support is also available.</p>"},{"location":"projects/celine-utils/docs/schemas/","title":"Governance Schemas","text":"<p>This folder contains JSON Schema definitions used by CELINE to formally describe custom metadata structures exchanged across the platform.</p> <p>The schemas are primarily intended for OpenLineage custom facets, validation, and interoperability between pipeline components, tooling, and external consumers.</p>"},{"location":"projects/celine-utils/docs/schemas/#purpose","title":"Purpose","text":"<p>The schemas in this folder serve as:</p> <ul> <li>Authoritative contracts for custom OpenLineage facets</li> <li>Validation targets for emitted lineage events</li> <li>Documentation artifacts describing governance and metadata semantics</li> <li>Stable references via <code>_schemaURL</code> fields in OpenLineage facets</li> </ul> <p>They ensure that lineage, governance, and metadata extensions remain consistent, machine-readable, and evolvable over time.</p>"},{"location":"projects/celine-utils/docs/schemas/#typical-contents","title":"Typical Contents","text":"<p>You will usually find schemas defining:</p> <ul> <li>Dataset-level custom facets (e.g. governance, ownership, classification)</li> <li>Field-level or schema-level metadata extensions</li> <li>CELINE-specific extensions that are not part of the OpenLineage core specification</li> </ul> <p>Each schema is written in JSON Schema format and is designed to be compatible with OpenLineage custom facet requirements.</p>"},{"location":"projects/celine-utils/docs/schemas/#usage","title":"Usage","text":"<p>Schemas in this folder are typically referenced by:</p> <ul> <li>Custom OpenLineage facets via the <code>_schemaURL</code> attribute</li> <li>Validation tooling during pipeline execution or CI</li> <li>Documentation and downstream metadata consumers</li> </ul> <p>Example reference from a custom facet:</p> <pre><code>{\n  \"_schemaURL\": \"https://raw.githubusercontent.com/celine-eu/celine-utils/main/schemas/GovernanceDatasetFacet.json\"\n}\n</code></pre>"},{"location":"projects/celine-utils/docs/schemas/#design-principles","title":"Design Principles","text":"<ul> <li>Backward compatible whenever possible</li> <li>Explicit and typed fields</li> <li>Stable URLs once published</li> <li>No runtime logic \u2014 schemas are declarative only</li> </ul> <p>Breaking changes should result in a new schema file, not a modification of an existing one.</p>"},{"location":"projects/celine-utils/docs/schemas/#relationship-to-the-platform","title":"Relationship to the Platform","text":"<p>These schemas are part of the broader CELINE tooling ecosystem and are consumed by pipeline runners, lineage emitters, governance resolvers, and external cataloging systems.</p>"},{"location":"projects/celine-utils/docs/schemas/#notes","title":"Notes","text":"<ul> <li>Do not embed secrets or environment-specific values in schemas</li> <li>Keep descriptions concise but precise</li> <li>Prefer clarity over cleverness</li> </ul> <p>For implementation details, refer to the corresponding facet or resolver code that uses each schema.</p>"},{"location":"projects/dataset-api/","title":"Dataset API","text":""},{"location":"projects/dataset-api/#overview","title":"Overview","text":"<p>The Dataset API provides a unified, lineage-aware, metadata-rich interface to datasets stored across heterogeneous backends (PostgreSQL, S3, filesystem). It exposes a DCAT-AP 3.0.0\u2013compatible catalogue, OpenLineage-enriched metadata, and a controlled dataset exposure policy.</p>"},{"location":"projects/dataset-api/#features","title":"Features","text":"<ul> <li>DCAT-AP 3.0.0 catalogue (<code>/catalogue</code>)</li> <li>Detailed dataset metadata (<code>/dataset/&lt;id&gt;/metadata</code>)</li> <li>Dataset schema (<code>/dataset/&lt;id&gt;/schema</code>)</li> <li>Query API using SQL-like syntax (<code>/dataset/&lt;id&gt;/query</code>)</li> <li>Strong governance through controlled dataset exposure (<code>expose: true/false</code>)</li> <li>OpenLineage integration and provenance tracking</li> <li>YAML-based catalogue import/export</li> <li>CLI tools for validation, extraction, import, and migration</li> <li>Backend-agnostic support for PostgreSQL, S3, and filesystem data</li> </ul>"},{"location":"projects/dataset-api/#architecture-summary","title":"Architecture Summary","text":"<ul> <li>Catalogue layer stored in PostgreSQL schema (<code>settings.catalogue_schema</code>)</li> <li>DatasetEntry model capturing backend config, tags, lineage, licensing, and metadata</li> <li>DCAT builders generate catalogue and dataset JSON-LD outputs</li> <li>OpenLineage extractor fetches metadata via Marquez and exports YAML</li> <li>Importer CLI loads YAML \u2192 validates via Pydantic \u2192 imports into catalogue DB</li> <li>Exposure semantics ensure only selected datasets are queryable</li> <li>Alembic migrations support async engines and schema scoping</li> </ul>"},{"location":"projects/dataset-api/#cli-commands","title":"CLI Commands","text":""},{"location":"projects/dataset-api/#export-openlineage-to-yaml","title":"Export OpenLineage to YAML","text":"<pre><code>dataset export openlineage --ns prod -o data/ --expose\n</code></pre>"},{"location":"projects/dataset-api/#import-catalogue-from-yaml","title":"Import catalogue from YAML","text":"<pre><code>dataset import catalogue -i data/*.yaml --api-url http://localhost:8000\n</code></pre>"},{"location":"projects/dataset-api/#validate-catalogue-files","title":"Validate catalogue file(s)","text":"<pre><code>dataset validate catalogue -i data/*.yaml --strict\n</code></pre>"},{"location":"projects/dataset-api/#alembic-migrations","title":"Alembic migrations","text":"<pre><code>uv run alembic upgrade head\nuv run alembic revision --autogenerate -m \"update\"\n</code></pre>"},{"location":"projects/dataset-api/#backends","title":"Backends","text":"<ul> <li>postgres \u2013 SQL tables</li> <li>s3 \u2013 raw objects with optional public URL</li> <li>fs \u2013 direct file-based datasets</li> </ul>"},{"location":"projects/dataset-api/#lineage-support","title":"Lineage Support","text":"<p>The system stores structured lineage metadata from OpenLineage, including: - namespace - sourceName - timestamps - lifecycle state - facets - tags</p> <p>Pydantic models allow flexible ingestion (<code>extra=\"allow\"</code>).</p>"},{"location":"projects/dataset-api/#dcat-ap-compliance","title":"DCAT-AP Compliance","text":"<p>Each dataset includes: - identifiers, titles, descriptions - keywords, themes - publisher, rights holder, license - language &amp; spatial coverage - distributions (API access and raw file access) - provenance (<code>prov:wasDerivedFrom</code>) using lineage information</p>"},{"location":"projects/dataset-api/#development","title":"Development","text":""},{"location":"projects/dataset-api/#dump-all-python-source-files-into-a-single-file","title":"Dump all Python source files into a single file:","text":"<p>A provided tool gathers all <code>dataset/**/*.py</code> into one bundle while ignoring <code>__pycache__</code>.</p>"},{"location":"projects/dataset-api/#supported-python-tooling","title":"Supported Python tooling:","text":"<ul> <li><code>uv</code> package runner</li> <li>Typer CLI</li> <li>Pydantic v2</li> <li>SQLAlchemy (async)</li> <li>Alembic (async migrations)</li> <li>httpx (async HTTP calls)</li> </ul>"},{"location":"projects/dataset-api/#license","title":"License","text":"<p>Copyright &gt;=2025 Spindox Labs</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p> <pre><code>http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"projects/dataset-api/#contributing","title":"Contributing","text":"<p>Ensure: - All YAML definitions validate via the CLI - No API endpoint accepts unvalidated data - Alembic migrations are generated for schema changes</p> <p>PRs should include tests for: - catalogue import - DCAT output - lineage extraction - backend resolution</p>"},{"location":"projects/dataset-api/ontologies/","title":"CELINE Ontology","text":"<p>This directory contains the semantic artifacts used in the CELINE project to support:</p> <ul> <li>semantic interoperability across datasets</li> <li>Digital Twins (WP3)</li> <li>Demonstrators, KPIs, and evaluation (WP5)</li> <li>mapping from tabular data to RDF / JSON-LD</li> </ul> <p>The CELINE ontology is not a standalone domain ontology, but a unified ontology profile that aligns and connects established standards (SAREF, SOSA, BIGG, SEAS, EM-KPI) into a coherent semantic target for the CELINE ecosystem.</p>"},{"location":"projects/dataset-api/ontologies/#contents","title":"Contents","text":""},{"location":"projects/dataset-api/ontologies/#core-ontology-artifacts","title":"Core ontology artifacts","text":"<ul> <li> <p>CELINE ontology documentation   Documentation of the CELINE ontology</p> </li> <li> <p>CELINE ontology (Turtle)   The formal OWL/RDF definition of the CELINE Unified Ontology Profile.   Defines CELINE classes and properties and aligns them with SAREF, SOSA, BIGG, SEAS, and EM-KPI.</p> </li> <li> <p>CELINE SHACL shapes   SHACL shapes defining semantic constraints on the RDF graph after JSON-LD expansion.   Used to validate observations, time series, meters, energy communities, and KPIs.</p> </li> <li> <p>CELINE JSON-LD context   JSON-LD <code>@context</code> defining prefixes, aliases, and mappings used by CELINE APIs and data pipelines.   This is the primary entry point for developers producing JSON-LD payloads.</p> </li> <li> <p>CELINE JSON Schema   JSON Schema used at API boundaries to validate incoming JSON-LD payloads before semantic expansion.</p> </li> </ul>"},{"location":"projects/dataset-api/ontologies/#repository-mapping-configuration","title":"Repository &amp; mapping configuration","text":"<ul> <li> <p>Open repository configuration   YAML configuration listing datasets, governance metadata, and extension points for ontology mapping.</p> </li> <li> <p>Open repository JSON Schema   JSON Schema defining the structure of the dataset catalogue and repository configuration used by CELINE tooling.</p> </li> </ul>"},{"location":"projects/dataset-api/ontologies/#how-these-artifacts-work-together","title":"How these artifacts work together","text":"<p>The CELINE semantic stack follows a layered validation and mapping approach:</p> <ol> <li>Tabular data is exposed via dataset APIs  </li> <li>Mapping definitions bind dataset schemas to ontology classes and properties  </li> <li>JSON-LD is generated using <code>celine.jsonld</code> </li> <li>JSON Schema (<code>celine.schema.json</code>) validates payload structure at the API level  </li> <li>JSON-LD expansion produces RDF  </li> <li>SHACL validation (<code>celine.shacl.ttl</code>) enforces semantic correctness  </li> <li>Validated data is ingested into the CELINE Digital Twin / Knowledge Graph</li> </ol> <p>This separation ensures: - developer-friendly APIs - strict semantic validation - long-term interoperability</p>"},{"location":"projects/dataset-api/ontologies/#design-principles","title":"Design principles","text":"<ul> <li>Standards first: reuse ETSI SAREF, W3C SOSA/SSN, BIGG, SEAS, EM-KPI</li> <li>Thin CELINE layer: only project-specific glue concepts are defined</li> <li>Modular &amp; versionable: artifacts can evolve independently</li> <li>Tool-friendly: compatible with rdflib, JSON-LD, SHACL engines</li> </ul>"},{"location":"projects/dataset-api/ontologies/#intended-audience","title":"Intended audience","text":"<ul> <li>CELINE developers integrating data sources</li> <li>WP3 Digital Twin engineers</li> <li>WP5 demonstrator and KPI designers</li> <li>Data governance and interoperability stakeholders</li> </ul>"},{"location":"projects/dataset-api/ontologies/#versioning-publication","title":"Versioning &amp; publication","text":"<p>These ontology artifacts are published via GitHub Pages to provide stable, resolvable URLs suitable for:</p> <ul> <li>JSON-LD contexts</li> <li>ontology references in catalogues</li> <li>external integrations</li> </ul> <p>Always prefer versioned URLs when referencing ontology artifacts in mappings or production systems.</p>"},{"location":"projects/dataset-api/ontologies/#questions-contributions","title":"Questions &amp; contributions","text":"<p>For questions, discussions, or proposed changes to the CELINE ontology profile, please refer to the main CELINE repository or open an issue in the relevant project repository.</p>"},{"location":"schema/","title":"Schema","text":"<ul> <li>governance.schema.json</li> <li>GovernanceDatasetFacet.schema.json</li> </ul>"}]}