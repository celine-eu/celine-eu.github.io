{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"CELINE documentation","text":"<p>Documentation for the CELINE project</p>"},{"location":"ontologies/","title":"CELINE Ontology","text":"<p>This directory contains the semantic artifacts used in the CELINE project to support:</p> <ul> <li>semantic interoperability across datasets</li> <li>Digital Twins (WP3)</li> <li>Demonstrators, KPIs, and evaluation (WP5)</li> <li>mapping from tabular data to RDF / JSON-LD</li> </ul> <p>The CELINE ontology is not a standalone domain ontology, but a unified ontology profile that aligns and connects established standards (SAREF, SOSA, BIGG, SEAS, EM-KPI) into a coherent semantic target for the CELINE ecosystem.</p>"},{"location":"ontologies/#contents","title":"Contents","text":""},{"location":"ontologies/#core-ontology-artifacts","title":"Core ontology artifacts","text":"<ul> <li> <p>CELINE JSON-LD context   JSON-LD <code>@context</code> defining prefixes, aliases, and mappings used by CELINE APIs and data pipelines.   This is the primary entry point for developers producing JSON-LD payloads.</p> </li> <li> <p>CELINE JSON Schema   JSON Schema used at API boundaries to validate incoming JSON-LD payloads before semantic expansion.</p> </li> <li> <p>CELINE ontology (Turtle)   The formal OWL/RDF definition of the CELINE Unified Ontology Profile.   Defines CELINE classes and properties and aligns them with SAREF, SOSA, BIGG, SEAS, and EM-KPI.</p> </li> <li> <p>CELINE SHACL shapes   SHACL shapes defining semantic constraints on the RDF graph after JSON-LD expansion.   Used to validate observations, time series, meters, energy communities, and KPIs.</p> </li> </ul>"},{"location":"ontologies/#repository-mapping-configuration","title":"Repository &amp; mapping configuration","text":"<ul> <li> <p>Open repository configuration   YAML configuration listing datasets, governance metadata, and extension points for ontology mapping.</p> </li> <li> <p>Open repository JSON Schema   JSON Schema defining the structure of the dataset catalogue and repository configuration used by CELINE tooling.</p> </li> </ul>"},{"location":"ontologies/#how-these-artifacts-work-together","title":"How these artifacts work together","text":"<p>The CELINE semantic stack follows a layered validation and mapping approach:</p> <ol> <li>Tabular data is exposed via dataset APIs  </li> <li>Mapping definitions bind dataset schemas to ontology classes and properties  </li> <li>JSON-LD is generated using <code>celine.jsonld</code> </li> <li>JSON Schema (<code>celine.schema.json</code>) validates payload structure at the API level  </li> <li>JSON-LD expansion produces RDF  </li> <li>SHACL validation (<code>celine.shacl.ttl</code>) enforces semantic correctness  </li> <li>Validated data is ingested into the CELINE Digital Twin / Knowledge Graph</li> </ol> <p>This separation ensures: - developer-friendly APIs - strict semantic validation - long-term interoperability</p>"},{"location":"ontologies/#design-principles","title":"Design principles","text":"<ul> <li>Standards first: reuse ETSI SAREF, W3C SOSA/SSN, BIGG, SEAS, EM-KPI</li> <li>Thin CELINE layer: only project-specific glue concepts are defined</li> <li>Modular &amp; versionable: artifacts can evolve independently</li> <li>Tool-friendly: compatible with rdflib, JSON-LD, SHACL engines</li> </ul>"},{"location":"ontologies/#intended-audience","title":"Intended audience","text":"<ul> <li>CELINE developers integrating data sources</li> <li>WP3 Digital Twin engineers</li> <li>WP5 demonstrator and KPI designers</li> <li>Data governance and interoperability stakeholders</li> </ul>"},{"location":"ontologies/#versioning-publication","title":"Versioning &amp; publication","text":"<p>These ontology artifacts are published via GitHub Pages to provide stable, resolvable URLs suitable for:</p> <ul> <li>JSON-LD contexts</li> <li>ontology references in catalogues</li> <li>external integrations</li> </ul> <p>Always prefer versioned URLs when referencing ontology artifacts in mappings or production systems.</p>"},{"location":"ontologies/#questions-contributions","title":"Questions &amp; contributions","text":"<p>For questions, discussions, or proposed changes to the CELINE ontology profile, please refer to the main CELINE repository or open an issue in the relevant project repository.</p>"},{"location":"projects/","title":"Tools","text":"<p>CELINE tools and services.</p>"},{"location":"projects/#dataset-api","title":"Dataset API","text":"<ul> <li>dataset-api</li> </ul>"},{"location":"projects/#celine-utils","title":"CELINE Utils","text":"<ul> <li>celine-utils</li> </ul>"},{"location":"projects/celine-utils/","title":"celine-tools","text":"<p><code>celine-tools</code> is a collection of utilities used across the CELINE data platform. It provides command-line tooling, runtime helpers, data governance resolution, dataset introspection, and pipeline lineage instrumentation for <code>dbt</code>, <code>Meltano</code>, and <code>OpenLineage</code>.</p> <p>This repository is intended to be embedded within applications deployed inside CELINE pipelines and orchestrated via Prefect, Meltano, and dbt.</p>"},{"location":"projects/celine-utils/#features-overview","title":"\ud83d\ude80 Features Overview","text":""},{"location":"projects/celine-utils/#1-command-line-interface-cli","title":"1. Command Line Interface (CLI)","text":"<p>A unified CLI implemented with Typer:</p> <pre><code>celine\n \u251c\u2500\u2500 admin\n \u2502    \u251c\u2500\u2500 keycloak\n \u2502    \u2514\u2500\u2500 setup\n \u251c\u2500\u2500 governance\n \u2502    \u2514\u2500\u2500 generate\n \u2514\u2500\u2500 pipeline\n      \u251c\u2500\u2500 run\n      \u2514\u2500\u2500 init\n</code></pre> <p>Key features include:</p> <ul> <li>Administrative helpers (Keycloak, Superset)</li> <li>Governance spec generation (docs/governance.md)</li> <li>Dataset metadata and querying tools</li> <li>Pipeline execution utilities for Meltano/dbt</li> <li>Pipeline application scaffolding (<code>celine pipeline init app</code>)</li> </ul>"},{"location":"projects/celine-utils/#2-keycloak-integration-layer","title":"2. Keycloak Integration Layer","text":"<p>Typed wrappers for <code>KeycloakAdmin</code> and <code>KeycloakOpenID</code>, providing:</p> <ul> <li>realm and user administration  </li> <li>client secret resolution  </li> <li>automatic token handling  </li> </ul>"},{"location":"projects/celine-utils/#3-superset-integration","title":"3. Superset Integration","text":"<p><code>SupersetClient</code> provides authenticated access to:</p> <ul> <li>list and create connections  </li> <li>manage datasets  </li> <li>integrate metadata into lineage and governance flows  </li> </ul>"},{"location":"projects/celine-utils/#4-dataset-introspection-and-querying","title":"4. Dataset Introspection and Querying","text":"<p><code>DatasetClient</code> supports:</p> <ul> <li>schema introspection  </li> <li>querying datasets  </li> <li>injection\u2011safe filtering  </li> <li>export to pandas  </li> </ul>"},{"location":"projects/celine-utils/#5-governance-framework","title":"5. Governance Framework","text":"<p>Pattern-based <code>governance.yaml</code> specification and resolver: - governance rules via pattern matching - OpenLineage facet enrichment - dbt assertion propagation  </p>"},{"location":"projects/celine-utils/#6-lineage-extraction-dbt-meltano","title":"6. Lineage Extraction (dbt &amp; Meltano)","text":"<p>Automatic lineage extraction enriched with: - schema metadata - governance patterns - dbt test results  </p>"},{"location":"projects/celine-utils/#7-pipeline-runner","title":"7. Pipeline Runner","text":"<p>The <code>PipelineRunner</code> orchestrates:</p> <ul> <li><code>meltano run</code></li> <li><code>dbt run</code>, <code>dbt test</code>, <code>dbt run-operation</code></li> <li>streaming logs  </li> <li>OpenLineage emission  </li> <li>governance enforcement  </li> </ul>"},{"location":"projects/celine-utils/#8-pipeline-application-scaffolding","title":"8. Pipeline Application Scaffolding","text":"<p><code>celine pipeline init app &lt;name&gt;</code> generates a fully structured pipeline application:</p> <pre><code>&lt;app_name&gt;/\n  meltano/\n    meltano.yml        # env-based config (${POSTGRES_HOST}, etc.)\n  dbt/\n    dbt_project.yml\n    profiles.yml       # uses env_var('VAR') for dynamic config\n    models/\n    tests/\n    macros/\n  flows/\n    pipeline.py\n  .env\n  README.md\n</code></pre> <p>A non-interactive, templated setup for: - Meltano - dbt - Python orchestration flows  </p>"},{"location":"projects/celine-utils/#9-configuration-system","title":"9. Configuration System","text":"<p>Based on <code>pydantic-settings</code>:</p> <ul> <li>environment variable driven  </li> <li><code>.env</code> / <code>.env.local</code> resolution  </li> <li>container-friendly defaults  </li> </ul>"},{"location":"projects/celine-utils/#10-mqtt-utility","title":"10. MQTT Utility","text":"<p>Simple MQTT client wrapper: - safe reconnects - pub/sub helpers - structured logging  </p>"},{"location":"projects/celine-utils/#folder-structure","title":"\ud83d\udcc1 Folder Structure","text":"<pre><code>celine/\n  admin/\n  cli/\n    commands/\n  common/\n  datasets/\n  pipelines/\n  docs/\n</code></pre>"},{"location":"projects/celine-utils/#installation","title":"\ud83d\udce6 Installation","text":"<pre><code>pip install celine-utils\n</code></pre>"},{"location":"projects/celine-utils/#license","title":"\ud83d\udcdd License","text":"<p>Copyright &gt;=2025 Spindox Labs</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0</p> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"projects/celine-utils/docs/governance/","title":"Governance Configuration","text":"<p>This document describes how dataset governance is defined, configured, and applied in CELINE pipelines using the <code>governance.yaml</code> file and the CELINE CLI.</p> <p>Governance metadata is used to enrich OpenLineage events, enforce consistency, and provide a single source of truth for ownership, licensing, access control, and classification.</p>"},{"location":"projects/celine-utils/docs/governance/#what-is-governanceyaml","title":"What Is <code>governance.yaml</code>","text":"<p><code>governance.yaml</code> is a declarative configuration file that defines governance rules for datasets produced or consumed by a pipeline.</p> <p>It allows you to specify, per dataset or dataset pattern:</p> <ul> <li>License</li> <li>Ownership</li> <li>Access level</li> <li>Classification / sensitivity</li> <li>Tags</li> <li>Retention policy</li> <li>Documentation and source system</li> </ul> <p>These rules are resolved at runtime and injected into lineage events as custom OpenLineage facets.</p>"},{"location":"projects/celine-utils/docs/governance/#where-the-file-lives","title":"Where the File Lives","text":"<p>For a pipeline application named <code>&lt;app_name&gt;</code>, the expected location is:</p> <pre><code>PIPELINES_ROOT/\n\u2514\u2500\u2500 apps/\n    \u2514\u2500\u2500 &lt;app_name&gt;/\n        \u2514\u2500\u2500 governance.yaml\n</code></pre> <p>The file is automatically discovered by CELINE tooling at runtime.</p> <p>You can override discovery using:</p> <pre><code>GOVERNANCE_CONFIG_PATH=/absolute/path/to/governance.yaml\n</code></pre>"},{"location":"projects/celine-utils/docs/governance/#file-structure","title":"File Structure","text":"<p>A <code>governance.yaml</code> file has two top-level sections:</p> <ul> <li><code>defaults</code>: applied to all datasets unless overridden</li> <li><code>sources</code>: dataset-specific or pattern-based rules</li> </ul>"},{"location":"projects/celine-utils/docs/governance/#example-governanceyaml","title":"Example <code>governance.yaml</code>","text":"<pre><code>defaults:\n  license: null\n  ownership: []\n  access_level: internal\n  classification: green\n  tags: []\n  retention_days: 365\n  documentation_url: https://example.com/dataset-test/docs\n  source_system: \"integration-tests\"\n\nsources:\n  datasets.ds.gold_color_metrics:\n    license: CC0-1.0\n    ownership:\n      - name: owner1\n        type: DATA_OWNER\n    access_level: internal\n    classification: green\n    tags:\n      - gold\n      - test\n\n  datasets.ds.silver_normalized:\n    license: ODbL-1.0\n    ownership:\n      - name: owner1\n        type: DATA_OWNER\n    access_level: internal\n    classification: yellow\n    tags:\n      - silver\n      - test\n\n  datasets.ds.stg_raw:\n    license: proprietary\n    ownership:\n      - name: company ltd\n        type: DATA_OWNER\n    access_level: restricted\n    classification: red\n    tags:\n      - raw\n      - test\n      - secret_sauce\n\n  datasets.raw.test:\n    license: proprietary\n    ownership:\n      - name: company foo\n        type: DATA_OWNER\n    access_level: secret\n    classification: red\n    tags:\n      - foo\n      - test\n      - raw\n\n  singer.tap-test.test:\n    license: proprietary\n    ownership: []\n    access_level: secret\n    classification: red\n    tags: []\n</code></pre>"},{"location":"projects/celine-utils/docs/governance/#defaults-section","title":"Defaults Section","text":"<p>The <code>defaults</code> block defines baseline governance applied to all datasets unless overridden.</p> <p>Typical use cases: - Global access level - Retention policy - Shared documentation URL - Default classification</p> <p>Fields set to <code>null</code> are omitted unless overridden.</p>"},{"location":"projects/celine-utils/docs/governance/#sources-section","title":"Sources Section","text":"<p>The <code>sources</code> section defines governance rules for specific datasets or patterns.</p>"},{"location":"projects/celine-utils/docs/governance/#dataset-keys","title":"Dataset Keys","text":"<p>Keys correspond to OpenLineage dataset names, for example:</p> <ul> <li><code>database.schema.table</code></li> <li><code>datasets.ds.gold_color_metrics</code></li> <li><code>singer.tap-test.test</code></li> </ul>"},{"location":"projects/celine-utils/docs/governance/#pattern-matching","title":"Pattern Matching","text":"<p>Wildcard rules are supported using glob semantics:</p> <pre><code>sources:\n  datasets.ds.*:\n    access_level: internal\n\n  datasets.raw.*:\n    classification: red\n</code></pre> <p>Resolution precedence: 1. Exact match 2. Longest matching wildcard 3. Defaults</p>"},{"location":"projects/celine-utils/docs/governance/#governance-fields","title":"Governance Fields","text":"Field Description <code>license</code> Dataset license identifier <code>ownership</code> List of owners (<code>name</code>, <code>type</code>) <code>access_level</code> <code>open</code>, <code>internal</code>, <code>restricted</code>, <code>secret</code> <code>classification</code> Sensitivity class (e.g. <code>green</code>, <code>yellow</code>, <code>red</code>) <code>tags</code> Free-form tags <code>retention_days</code> Retention period in days <code>documentation_url</code> Link to documentation <code>source_system</code> Origin system or domain"},{"location":"projects/celine-utils/docs/governance/#how-governance-is-applied","title":"How Governance Is Applied","text":"<p>During pipeline execution:</p> <ul> <li>Dataset lineage is collected</li> <li>Dataset names are resolved against <code>governance.yaml</code></li> <li>Defaults and overrides are merged</li> <li>Governance is emitted as a custom OpenLineage dataset facet</li> </ul> <p>This applies to: - Inputs - Outputs - dbt test datasets</p>"},{"location":"projects/celine-utils/docs/governance/#interactive-cli-usage","title":"Interactive CLI Usage","text":"<p>CELINE provides an interactive CLI to generate governance files.</p>"},{"location":"projects/celine-utils/docs/governance/#command","title":"Command","text":"<pre><code>celine governance generate marquez --app &lt;app_name&gt;\n</code></pre> <p>The CLI will: 1. Discover datasets from Marquez 2. Prompt for governance metadata per dataset 3. Allow pattern-based scoping 4. Write <code>governance.yaml</code> to the pipeline folder</p>"},{"location":"projects/celine-utils/docs/governance/#non-interactive-mode","title":"Non-Interactive Mode","text":"<p>For automation:</p> <pre><code>celine governance generate marquez --app &lt;app_name&gt; --yes\n</code></pre> <p>This generates a skeleton file using defaults.</p>"},{"location":"projects/celine-utils/docs/governance/#best-practices","title":"Best Practices","text":"<ul> <li>Use defaults to minimize repetition</li> <li>Prefer wildcard rules for schema-level governance</li> <li>Keep dataset names stable</li> <li>Version governance files with code</li> <li>Treat governance as configuration, not logic</li> </ul>"},{"location":"projects/celine-utils/docs/governance/#summary","title":"Summary","text":"<p><code>governance.yaml</code> provides a single, declarative mechanism for defining dataset governance in CELINE pipelines.</p> <p>It is: - Pattern-based - Automatically applied - Integrated with lineage - CLI-assisted</p>"},{"location":"projects/celine-utils/docs/schemas/","title":"Governance Schemas","text":"<p>This folder contains JSON Schema definitions used by CELINE to formally describe custom metadata structures exchanged across the platform.</p> <p>The schemas are primarily intended for OpenLineage custom facets, validation, and interoperability between pipeline components, tooling, and external consumers.</p>"},{"location":"projects/celine-utils/docs/schemas/#purpose","title":"Purpose","text":"<p>The schemas in this folder serve as:</p> <ul> <li>Authoritative contracts for custom OpenLineage facets</li> <li>Validation targets for emitted lineage events</li> <li>Documentation artifacts describing governance and metadata semantics</li> <li>Stable references via <code>_schemaURL</code> fields in OpenLineage facets</li> </ul> <p>They ensure that lineage, governance, and metadata extensions remain consistent, machine-readable, and evolvable over time.</p>"},{"location":"projects/celine-utils/docs/schemas/#typical-contents","title":"Typical Contents","text":"<p>You will usually find schemas defining:</p> <ul> <li>Dataset-level custom facets (e.g. governance, ownership, classification)</li> <li>Field-level or schema-level metadata extensions</li> <li>CELINE-specific extensions that are not part of the OpenLineage core specification</li> </ul> <p>Each schema is written in JSON Schema format and is designed to be compatible with OpenLineage custom facet requirements.</p>"},{"location":"projects/celine-utils/docs/schemas/#usage","title":"Usage","text":"<p>Schemas in this folder are typically referenced by:</p> <ul> <li>Custom OpenLineage facets via the <code>_schemaURL</code> attribute</li> <li>Validation tooling during pipeline execution or CI</li> <li>Documentation and downstream metadata consumers</li> </ul> <p>Example reference from a custom facet:</p> <pre><code>{\n  \"_schemaURL\": \"https://raw.githubusercontent.com/celine-eu/celine-utils/main/schemas/GovernanceDatasetFacet.json\"\n}\n</code></pre>"},{"location":"projects/celine-utils/docs/schemas/#design-principles","title":"Design Principles","text":"<ul> <li>Backward compatible whenever possible</li> <li>Explicit and typed fields</li> <li>Stable URLs once published</li> <li>No runtime logic \u2014 schemas are declarative only</li> </ul> <p>Breaking changes should result in a new schema file, not a modification of an existing one.</p>"},{"location":"projects/celine-utils/docs/schemas/#relationship-to-the-platform","title":"Relationship to the Platform","text":"<p>These schemas are part of the broader CELINE tooling ecosystem and are consumed by pipeline runners, lineage emitters, governance resolvers, and external cataloging systems.</p>"},{"location":"projects/celine-utils/docs/schemas/#notes","title":"Notes","text":"<ul> <li>Do not embed secrets or environment-specific values in schemas</li> <li>Keep descriptions concise but precise</li> <li>Prefer clarity over cleverness</li> </ul> <p>For implementation details, refer to the corresponding facet or resolver code that uses each schema.</p>"},{"location":"projects/dataset-api/","title":"Dataset API","text":""},{"location":"projects/dataset-api/#overview","title":"Overview","text":"<p>The Dataset API provides a unified, lineage-aware, metadata-rich interface to datasets stored across heterogeneous backends (PostgreSQL, S3, filesystem). It exposes a DCAT-AP 3.0.0\u2013compatible catalogue, OpenLineage-enriched metadata, and a controlled dataset exposure policy.</p>"},{"location":"projects/dataset-api/#features","title":"Features","text":"<ul> <li>DCAT-AP 3.0.0 catalogue (<code>/catalogue</code>)</li> <li>Detailed dataset metadata (<code>/dataset/&lt;id&gt;/metadata</code>)</li> <li>Dataset schema (<code>/dataset/&lt;id&gt;/schema</code>)</li> <li>Query API using SQL-like syntax (<code>/dataset/&lt;id&gt;/query</code>)</li> <li>Strong governance through controlled dataset exposure (<code>expose: true/false</code>)</li> <li>OpenLineage integration and provenance tracking</li> <li>YAML-based catalogue import/export</li> <li>CLI tools for validation, extraction, import, and migration</li> <li>Backend-agnostic support for PostgreSQL, S3, and filesystem data</li> </ul>"},{"location":"projects/dataset-api/#architecture-summary","title":"Architecture Summary","text":"<ul> <li>Catalogue layer stored in PostgreSQL schema (<code>settings.catalogue_schema</code>)</li> <li>DatasetEntry model capturing backend config, tags, lineage, licensing, and metadata</li> <li>DCAT builders generate catalogue and dataset JSON-LD outputs</li> <li>OpenLineage extractor fetches metadata via Marquez and exports YAML</li> <li>Importer CLI loads YAML \u2192 validates via Pydantic \u2192 imports into catalogue DB</li> <li>Exposure semantics ensure only selected datasets are queryable</li> <li>Alembic migrations support async engines and schema scoping</li> </ul>"},{"location":"projects/dataset-api/#cli-commands","title":"CLI Commands","text":""},{"location":"projects/dataset-api/#export-openlineage-to-yaml","title":"Export OpenLineage to YAML","text":"<pre><code>dataset export openlineage --ns prod -o data/ --expose\n</code></pre>"},{"location":"projects/dataset-api/#import-catalogue-from-yaml","title":"Import catalogue from YAML","text":"<pre><code>dataset import catalogue -i data/*.yaml --api-url http://localhost:8000\n</code></pre>"},{"location":"projects/dataset-api/#validate-catalogue-files","title":"Validate catalogue file(s)","text":"<pre><code>dataset validate catalogue -i data/*.yaml --strict\n</code></pre>"},{"location":"projects/dataset-api/#alembic-migrations","title":"Alembic migrations","text":"<pre><code>uv run alembic upgrade head\nuv run alembic revision --autogenerate -m \"update\"\n</code></pre>"},{"location":"projects/dataset-api/#backends","title":"Backends","text":"<ul> <li>postgres \u2013 SQL tables</li> <li>s3 \u2013 raw objects with optional public URL</li> <li>fs \u2013 direct file-based datasets</li> </ul>"},{"location":"projects/dataset-api/#lineage-support","title":"Lineage Support","text":"<p>The system stores structured lineage metadata from OpenLineage, including: - namespace - sourceName - timestamps - lifecycle state - facets - tags</p> <p>Pydantic models allow flexible ingestion (<code>extra=\"allow\"</code>).</p>"},{"location":"projects/dataset-api/#dcat-ap-compliance","title":"DCAT-AP Compliance","text":"<p>Each dataset includes: - identifiers, titles, descriptions - keywords, themes - publisher, rights holder, license - language &amp; spatial coverage - distributions (API access and raw file access) - provenance (<code>prov:wasDerivedFrom</code>) using lineage information</p>"},{"location":"projects/dataset-api/#development","title":"Development","text":""},{"location":"projects/dataset-api/#dump-all-python-source-files-into-a-single-file","title":"Dump all Python source files into a single file:","text":"<p>A provided tool gathers all <code>dataset/**/*.py</code> into one bundle while ignoring <code>__pycache__</code>.</p>"},{"location":"projects/dataset-api/#supported-python-tooling","title":"Supported Python tooling:","text":"<ul> <li><code>uv</code> package runner</li> <li>Typer CLI</li> <li>Pydantic v2</li> <li>SQLAlchemy (async)</li> <li>Alembic (async migrations)</li> <li>httpx (async HTTP calls)</li> </ul>"},{"location":"projects/dataset-api/#license","title":"License","text":"<p>Copyright &gt;=2025 Spindox Labs</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p> <pre><code>http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"projects/dataset-api/#contributing","title":"Contributing","text":"<p>Ensure: - All YAML definitions validate via the CLI - No API endpoint accepts unvalidated data - Alembic migrations are generated for schema changes</p> <p>PRs should include tests for: - catalogue import - DCAT output - lineage extraction - backend resolution</p>"},{"location":"projects/dataset-api/ontologies/","title":"CELINE Ontology","text":"<p>This directory contains the semantic artifacts used in the CELINE project to support:</p> <ul> <li>semantic interoperability across datasets</li> <li>Digital Twins (WP3)</li> <li>Demonstrators, KPIs, and evaluation (WP5)</li> <li>mapping from tabular data to RDF / JSON-LD</li> </ul> <p>The CELINE ontology is not a standalone domain ontology, but a unified ontology profile that aligns and connects established standards (SAREF, SOSA, BIGG, SEAS, EM-KPI) into a coherent semantic target for the CELINE ecosystem.</p>"},{"location":"projects/dataset-api/ontologies/#contents","title":"Contents","text":""},{"location":"projects/dataset-api/ontologies/#core-ontology-artifacts","title":"Core ontology artifacts","text":"<ul> <li> <p>CELINE JSON-LD context   JSON-LD <code>@context</code> defining prefixes, aliases, and mappings used by CELINE APIs and data pipelines.   This is the primary entry point for developers producing JSON-LD payloads.</p> </li> <li> <p>CELINE JSON Schema   JSON Schema used at API boundaries to validate incoming JSON-LD payloads before semantic expansion.</p> </li> <li> <p>CELINE ontology (Turtle)   The formal OWL/RDF definition of the CELINE Unified Ontology Profile.   Defines CELINE classes and properties and aligns them with SAREF, SOSA, BIGG, SEAS, and EM-KPI.</p> </li> <li> <p>CELINE SHACL shapes   SHACL shapes defining semantic constraints on the RDF graph after JSON-LD expansion.   Used to validate observations, time series, meters, energy communities, and KPIs.</p> </li> </ul>"},{"location":"projects/dataset-api/ontologies/#repository-mapping-configuration","title":"Repository &amp; mapping configuration","text":"<ul> <li> <p>Open repository configuration   YAML configuration listing datasets, governance metadata, and extension points for ontology mapping.</p> </li> <li> <p>Open repository JSON Schema   JSON Schema defining the structure of the dataset catalogue and repository configuration used by CELINE tooling.</p> </li> </ul>"},{"location":"projects/dataset-api/ontologies/#how-these-artifacts-work-together","title":"How these artifacts work together","text":"<p>The CELINE semantic stack follows a layered validation and mapping approach:</p> <ol> <li>Tabular data is exposed via dataset APIs  </li> <li>Mapping definitions bind dataset schemas to ontology classes and properties  </li> <li>JSON-LD is generated using <code>celine.jsonld</code> </li> <li>JSON Schema (<code>celine.schema.json</code>) validates payload structure at the API level  </li> <li>JSON-LD expansion produces RDF  </li> <li>SHACL validation (<code>celine.shacl.ttl</code>) enforces semantic correctness  </li> <li>Validated data is ingested into the CELINE Digital Twin / Knowledge Graph</li> </ol> <p>This separation ensures: - developer-friendly APIs - strict semantic validation - long-term interoperability</p>"},{"location":"projects/dataset-api/ontologies/#design-principles","title":"Design principles","text":"<ul> <li>Standards first: reuse ETSI SAREF, W3C SOSA/SSN, BIGG, SEAS, EM-KPI</li> <li>Thin CELINE layer: only project-specific glue concepts are defined</li> <li>Modular &amp; versionable: artifacts can evolve independently</li> <li>Tool-friendly: compatible with rdflib, JSON-LD, SHACL engines</li> </ul>"},{"location":"projects/dataset-api/ontologies/#intended-audience","title":"Intended audience","text":"<ul> <li>CELINE developers integrating data sources</li> <li>WP3 Digital Twin engineers</li> <li>WP5 demonstrator and KPI designers</li> <li>Data governance and interoperability stakeholders</li> </ul>"},{"location":"projects/dataset-api/ontologies/#versioning-publication","title":"Versioning &amp; publication","text":"<p>These ontology artifacts are published via GitHub Pages to provide stable, resolvable URLs suitable for:</p> <ul> <li>JSON-LD contexts</li> <li>ontology references in catalogues</li> <li>external integrations</li> </ul> <p>Always prefer versioned URLs when referencing ontology artifacts in mappings or production systems.</p>"},{"location":"projects/dataset-api/ontologies/#questions-contributions","title":"Questions &amp; contributions","text":"<p>For questions, discussions, or proposed changes to the CELINE ontology profile, please refer to the main CELINE repository or open an issue in the relevant project repository.</p>"}]}